{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def to_3arr(initial_conll_path, save=False, save_conll_path=None): \n",
    "    sentences = []\n",
    "    sent_tmp = []   \n",
    "    bio_tmp = []\n",
    "    _3arr = []\n",
    "    try:\n",
    "        file = open(initial_conll_path, encoding = 'utf8')\n",
    "        lines = file.readlines()\n",
    "        for index, line in enumerate(lines):\n",
    "            parse_word = line.strip().replace(u'\\ufeff', '').split('\\t')\n",
    "            if len(parse_word) == 2:\n",
    "                word = parse_word[0]\n",
    "                word_bio = parse_word[1]\n",
    "                sent_tmp.append(word)\n",
    "                bio_tmp.append(word_bio)\n",
    "                if index == len(lines) - 1:\n",
    "                    sent_pos_tag = nltk.pos_tag(sent_tmp)\n",
    "                    for index, item in enumerate(sent_pos_tag):\n",
    "                        tmp_tup = item + (bio_tmp[index], )\n",
    "                        _3arr.append(tmp_tup)\n",
    "                    if save:\n",
    "                        _3arr.append((np.nan,)) # a sentence end with NaN\n",
    "                        sentences.extend(_3arr)\n",
    "                    else:\n",
    "                        sentences.append(_3arr)\n",
    "            else:\n",
    "                sent_pos_tag = nltk.pos_tag(sent_tmp)\n",
    "                for index, item in enumerate(sent_pos_tag):\n",
    "                    tmp_tup = item + (bio_tmp[index], )\n",
    "                    _3arr.append(tmp_tup)\n",
    "                if save:\n",
    "                        _3arr.append((np.nan,)) # a sentence end with NaN\n",
    "                        sentences.extend(_3arr)\n",
    "                else:\n",
    "                    sentences.append(_3arr)\n",
    "                sent_tmp = []\n",
    "                bio_tmp = []\n",
    "                _3arr = []\n",
    "    finally:\n",
    "        if file:\n",
    "            file.close()\n",
    "\n",
    "    if save:\n",
    "        df = pandas.DataFrame(data=sentences)\n",
    "        df.to_csv(save_conll_path, index=None, header=None, sep='\\t')\n",
    "        return\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "def sent2pos(sent):\n",
    "    return [postag for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Get statistics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain triple array\n",
    "train_sents = to_3arr('wnut17train.conll')\n",
    "test_sents = to_3arr('emerging.test.annotated')\n",
    "dev_sents = to_3arr('emerging.dev.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numer of sentences:  3394\n",
      "numer of sentences:  1009\n",
      "numer of sentences:  1287\n"
     ]
    }
   ],
   "source": [
    "# sents\n",
    "print('numer of sentences: ', len(train_sents))\n",
    "print('numer of sentences: ', len(dev_sents))\n",
    "print('numer of sentences: ', len(test_sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66123\n",
      "16741\n",
      "24680\n"
     ]
    }
   ],
   "source": [
    "# tokens/words\n",
    "train_file = open('wnut17train.conll', encoding = 'utf8')\n",
    "dev_file = open('emerging.dev.conll', encoding = 'utf8')\n",
    "test_file = open('emerging.test.annotated', encoding = 'utf8')\n",
    "train_lines = train_file.readlines()\n",
    "dev_lines = dev_file.readlines()\n",
    "test_lines = test_file.readlines()\n",
    "print(len(train_lines))\n",
    "print(len(dev_lines))\n",
    "print(len(test_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get types for POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJR',\n",
       " 'NNPS',\n",
       " 'VBG',\n",
       " 'PRP',\n",
       " 'NNS',\n",
       " 'VBZ',\n",
       " 'VBP',\n",
       " 'RBS',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'WRB',\n",
       " 'POS',\n",
       " 'WP',\n",
       " 'MD',\n",
       " 'IN',\n",
       " 'RP',\n",
       " \"''\",\n",
       " 'VB',\n",
       " 'FW',\n",
       " 'JJS',\n",
       " 'PRP$',\n",
       " 'RBR',\n",
       " 'PDT',\n",
       " 'NN',\n",
       " 'VBN',\n",
       " 'JJ',\n",
       " 'EX',\n",
       " 'RB',\n",
       " 'NNP',\n",
       " 'TO',\n",
       " 'SYM',\n",
       " 'UH',\n",
       " 'CC',\n",
       " 'WDT',\n",
       " 'VBD']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "y_train_pos = [sent2pos(s) for s in train_sents]\n",
    "tmp_pos = []\n",
    "for pos in y_train_pos:\n",
    "    tmp_pos += list(set(pos))\n",
    "type_pos = list(set(tmp_pos))\n",
    "type_pos = [type for type in type_pos if type not in string.punctuation]\n",
    "type_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and labels of sets\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Run a baseline run (train -> test) with the features directly copied from the tutorial. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-location', 'I-location', 'B-group', 'B-corporation', 'B-person', 'B-creative-work', 'B-product', 'I-person', 'I-creative-work', 'I-corporation', 'I-group', 'I-product']\n"
     ]
    }
   ],
   "source": [
    "# train and use L-BFGS\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(labels) # get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13532451620051908\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.308     0.028     0.052       142\n",
      "I-creative-work      0.333     0.032     0.059       218\n",
      "        B-group      0.263     0.030     0.054       165\n",
      "        I-group      0.200     0.029     0.050        70\n",
      "     B-location      0.391     0.227     0.287       150\n",
      "     I-location      0.250     0.064     0.102        94\n",
      "       B-person      0.563     0.135     0.218       429\n",
      "       I-person      0.560     0.214     0.309       131\n",
      "      B-product      0.500     0.024     0.045       127\n",
      "      I-product      0.333     0.048     0.083       126\n",
      "\n",
      "      micro avg      0.432     0.088     0.146      1740\n",
      "      macro avg      0.308     0.069     0.105      1740\n",
      "   weighted avg      0.389     0.088     0.135      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Hyperparameters Optimization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B5024CC7F0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, labels=['B-location', 'I-location', 'B-group', 'B-corporation', 'B-person', 'B-creative-work', 'B-product', 'I-person', 'I-creative-work', 'I-corporation', 'I-group', 'I-product'], average=weighted),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c2': 0.04512332140157257, 'c1': 0.008130349084185253}\n",
      "best CV score: 0.3629082087042693\n",
      "model size: 0.63M\n"
     ]
    }
   ],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21047584355082335\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.500     0.015     0.029        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.181     0.092     0.121       142\n",
      "I-creative-work      0.196     0.225     0.209       218\n",
      "        B-group      0.333     0.006     0.012       165\n",
      "        I-group      0.600     0.043     0.080        70\n",
      "     B-location      0.400     0.187     0.255       150\n",
      "     I-location      0.238     0.053     0.087        94\n",
      "       B-person      0.461     0.375     0.414       429\n",
      "       I-person      0.437     0.344     0.385       131\n",
      "      B-product      0.143     0.079     0.102       127\n",
      "      I-product      0.078     0.040     0.053       126\n",
      "\n",
      "      micro avg      0.318     0.184     0.233      1740\n",
      "      macro avg      0.297     0.121     0.146      1740\n",
      "   weighted avg      0.324     0.184     0.210      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "# crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features_custom(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i == 1:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i > 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        word3 = sent[i-3][0]\n",
    "        postag3 = sent[i-3][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "            '-3:word.lower()': word3.lower(),\n",
    "            '-3:word.istitle()': word3.istitle(),\n",
    "            '-3:word.isupper()': word3.isupper(),\n",
    "            '-3:postag': postag3,\n",
    "            '-3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i == len(sent)-2:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i < len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        word3 = sent[i+3][0]\n",
    "        postag3 = sent[i+3][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "            '+3:word.lower()': word3.lower(),\n",
    "            '+3:word.istitle()': word3.istitle(),\n",
    "            '+3:word.isupper()': word3.isupper(),\n",
    "            '+3:postag': postag3,\n",
    "            '+3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features_custom(sent):\n",
    "    return [word2features_custom(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain triple array\n",
    "train_sents = to_3arr('wnut17train.conll')\n",
    "test_sents = to_3arr('emerging.test.annotated')\n",
    "dev_sents = to_3arr('emerging.dev.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and labels of sets\n",
    "X_train = [sent2features_custom(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_custom(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_custom(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13791016470926343\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.200     0.021     0.038       142\n",
      "I-creative-work      0.265     0.041     0.071       218\n",
      "        B-group      0.353     0.036     0.066       165\n",
      "        I-group      0.400     0.086     0.141        70\n",
      "     B-location      0.405     0.200     0.268       150\n",
      "     I-location      0.214     0.064     0.098        94\n",
      "       B-person      0.512     0.147     0.228       429\n",
      "       I-person      0.451     0.244     0.317       131\n",
      "      B-product      0.250     0.008     0.015       127\n",
      "      I-product      0.400     0.032     0.059       126\n",
      "\n",
      "      micro avg      0.405     0.092     0.150      1740\n",
      "      macro avg      0.288     0.073     0.109      1740\n",
      "   weighted avg      0.353     0.092     0.138      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and use L-BFGS\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000211F3F17400>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, labels=['B-location', 'I-location', 'B-group', 'B-corporation', 'B-person', 'B-creative-work', 'B-product', 'I-person', 'I-creative-work', 'I-corporation', 'I-group', 'I-product'], average=weighted),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18781321926080463\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.500     0.015     0.029        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.151     0.056     0.082       142\n",
      "I-creative-work      0.183     0.138     0.157       218\n",
      "        B-group      0.000     0.000     0.000       165\n",
      "        I-group      0.000     0.000     0.000        70\n",
      "     B-location      0.359     0.153     0.215       150\n",
      "     I-location      0.280     0.074     0.118        94\n",
      "       B-person      0.435     0.361     0.395       429\n",
      "       I-person      0.390     0.298     0.338       131\n",
      "      B-product      0.150     0.047     0.072       127\n",
      "      I-product      0.180     0.071     0.102       126\n",
      "\n",
      "      micro avg      0.324     0.160     0.214      1740\n",
      "      macro avg      0.219     0.101     0.126      1740\n",
      "   weighted avg      0.261     0.160     0.188      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14508507753093186\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.267     0.028     0.051       142\n",
      "I-creative-work      0.273     0.041     0.072       218\n",
      "        B-group      0.357     0.030     0.056       165\n",
      "        I-group      0.500     0.100     0.167        70\n",
      "     B-location      0.431     0.207     0.279       150\n",
      "     I-location      0.241     0.074     0.114        94\n",
      "       B-person      0.511     0.156     0.239       429\n",
      "       I-person      0.479     0.260     0.337       131\n",
      "      B-product      0.250     0.008     0.015       127\n",
      "      I-product      0.400     0.032     0.059       126\n",
      "\n",
      "      micro avg      0.427     0.097     0.158      1740\n",
      "      macro avg      0.309     0.078     0.116      1740\n",
      "   weighted avg      0.369     0.097     0.145      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and use L-BFGS\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F2EF5C5E48>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-location', 'I-location', 'B-group', 'B-corporation', 'B-person', 'B-creative-work', 'B-product', 'I-person', 'I-creative-work', 'I-corporation', 'I-group', 'I-product']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18072571686206085\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      1.000     0.015     0.030        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.155     0.063     0.090       142\n",
      "I-creative-work      0.182     0.133     0.154       218\n",
      "        B-group      0.000     0.000     0.000       165\n",
      "        I-group      0.000     0.000     0.000        70\n",
      "     B-location      0.371     0.153     0.217       150\n",
      "     I-location      0.292     0.074     0.119        94\n",
      "       B-person      0.445     0.338     0.384       429\n",
      "       I-person      0.443     0.267     0.333       131\n",
      "      B-product      0.125     0.031     0.050       127\n",
      "      I-product      0.128     0.040     0.061       126\n",
      "\n",
      "      micro avg      0.329     0.148     0.204      1740\n",
      "      macro avg      0.262     0.093     0.120      1740\n",
      "   weighted avg      0.283     0.148     0.181      1740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Extend features-->train->test, and dev->test using RS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Custom features adding punctuation-train->test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14399274320874095\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.250     0.028     0.051       142\n",
      "I-creative-work      0.303     0.046     0.080       218\n",
      "        B-group      0.286     0.036     0.065       165\n",
      "        I-group      0.312     0.071     0.116        70\n",
      "     B-location      0.387     0.240     0.296       150\n",
      "     I-location      0.304     0.074     0.120        94\n",
      "       B-person      0.569     0.135     0.218       429\n",
      "       I-person      0.583     0.214     0.313       131\n",
      "      B-product      0.600     0.024     0.045       127\n",
      "      I-product      0.545     0.048     0.088       126\n",
      "\n",
      "      micro avg      0.439     0.094     0.154      1740\n",
      "      macro avg      0.345     0.076     0.116      1740\n",
      "   weighted avg      0.415     0.094     0.144      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def word2features_custom_punctuation(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.ispunctuation()': 1 if word.lower() in string.punctuation else 0,\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features_punctuation(sent):\n",
    "    return [word2features_custom_punctuation(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# extract features and labels of sets\n",
    "X_train = [sent2features_punctuation(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_punctuation(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_punctuation(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Custom features adding punctuation-dev->test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19827866061584476\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      1.000     0.015     0.030        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.143     0.077     0.100       142\n",
      "I-creative-work      0.151     0.202     0.173       218\n",
      "        B-group      0.000     0.000     0.000       165\n",
      "        I-group      0.000     0.000     0.000        70\n",
      "     B-location      0.425     0.207     0.278       150\n",
      "     I-location      0.208     0.053     0.085        94\n",
      "       B-person      0.474     0.357     0.407       429\n",
      "       I-person      0.434     0.328     0.374       131\n",
      "      B-product      0.138     0.071     0.094       127\n",
      "      I-product      0.060     0.040     0.048       126\n",
      "\n",
      "      micro avg      0.289     0.174     0.217      1740\n",
      "      macro avg      0.253     0.112     0.132      1740\n",
      "   weighted avg      0.280     0.174     0.198      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)\n",
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Custom features adding stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13846223169257973\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.357     0.035     0.064       142\n",
      "I-creative-work      0.393     0.050     0.089       218\n",
      "        B-group      0.250     0.024     0.044       165\n",
      "        I-group      0.286     0.029     0.052        70\n",
      "     B-location      0.396     0.240     0.299       150\n",
      "     I-location      0.407     0.117     0.182        94\n",
      "       B-person      0.556     0.128     0.208       429\n",
      "       I-person      0.562     0.206     0.302       131\n",
      "      B-product      0.500     0.016     0.031       127\n",
      "      I-product      0.167     0.032     0.053       126\n",
      "\n",
      "      micro avg      0.435     0.090     0.149      1740\n",
      "      macro avg      0.323     0.073     0.110      1740\n",
      "   weighted avg      0.398     0.090     0.138      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "def word2features_custom_stem(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.stem()': stemmer.stem(word.lower()),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features_stem(sent):\n",
    "    return [word2features_custom_stem(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# extract features and labels of sets\n",
    "X_train = [sent2features_stem(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_stem(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_stem(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.5min finished\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21340399245544067\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.500     0.015     0.029        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.176     0.092     0.120       142\n",
      "I-creative-work      0.189     0.225     0.205       218\n",
      "        B-group      0.333     0.006     0.012       165\n",
      "        I-group      0.600     0.043     0.080        70\n",
      "     B-location      0.431     0.187     0.260       150\n",
      "     I-location      0.300     0.064     0.105        94\n",
      "       B-person      0.477     0.364     0.413       429\n",
      "       I-person      0.462     0.366     0.409       131\n",
      "      B-product      0.120     0.071     0.089       127\n",
      "      I-product      0.103     0.056     0.072       126\n",
      "\n",
      "      micro avg      0.320     0.184     0.234      1740\n",
      "      macro avg      0.308     0.124     0.150      1740\n",
      "   weighted avg      0.335     0.184     0.213      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)\n",
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Custom features adding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14096956171765285\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.286     0.028     0.051       142\n",
      "I-creative-work      0.350     0.032     0.059       218\n",
      "        B-group      0.294     0.030     0.055       165\n",
      "        I-group      0.222     0.029     0.051        70\n",
      "     B-location      0.358     0.227     0.278       150\n",
      "     I-location      0.269     0.074     0.117        94\n",
      "       B-person      0.606     0.147     0.236       429\n",
      "       I-person      0.592     0.221     0.322       131\n",
      "      B-product      0.600     0.024     0.045       127\n",
      "      I-product      0.353     0.048     0.084       126\n",
      "\n",
      "      micro avg      0.446     0.092     0.152      1740\n",
      "      macro avg      0.327     0.072     0.108      1740\n",
      "   weighted avg      0.413     0.092     0.141      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def word2features_custom_stopwords(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isstopword()': 1 if word.lower() in stop_words else 0,\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features_stopwords(sent):\n",
    "    return [word2features_custom_stopwords(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# extract features and labels of sets\n",
    "X_train = [sent2features_stopwords(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_stopwords(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_stopwords(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.4min finished\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000262215769624\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.171     0.085     0.113       142\n",
      "I-creative-work      0.157     0.170     0.163       218\n",
      "        B-group      0.200     0.006     0.012       165\n",
      "        I-group      0.200     0.043     0.071        70\n",
      "     B-location      0.342     0.167     0.224       150\n",
      "     I-location      0.227     0.053     0.086        94\n",
      "       B-person      0.451     0.378     0.411       429\n",
      "       I-person      0.433     0.397     0.414       131\n",
      "      B-product      0.117     0.071     0.088       127\n",
      "      I-product      0.058     0.040     0.047       126\n",
      "\n",
      "      micro avg      0.293     0.179     0.222      1740\n",
      "      macro avg      0.196     0.117     0.136      1740\n",
      "   weighted avg      0.259     0.179     0.200      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)\n",
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Custom features adding -+3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13811565438887777\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.200     0.021     0.038       142\n",
      "I-creative-work      0.281     0.041     0.072       218\n",
      "        B-group      0.333     0.030     0.056       165\n",
      "        I-group      0.429     0.086     0.143        70\n",
      "     B-location      0.413     0.207     0.276       150\n",
      "     I-location      0.250     0.074     0.115        94\n",
      "       B-person      0.508     0.147     0.228       429\n",
      "       I-person      0.456     0.237     0.312       131\n",
      "      B-product      0.250     0.008     0.015       127\n",
      "      I-product      0.400     0.032     0.059       126\n",
      "\n",
      "      micro avg      0.412     0.092     0.150      1740\n",
      "      macro avg      0.293     0.074     0.109      1740\n",
      "   weighted avg      0.356     0.092     0.138      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def word2features_custom_3words(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i == 1:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i > 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        word3 = sent[i-3][0]\n",
    "        postag3 = sent[i-3][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "            '-3:word.lower()': word3.lower(),\n",
    "            '-3:word.istitle()': word3.istitle(),\n",
    "            '-3:word.isupper()': word3.isupper(),\n",
    "            '-3:postag': postag3,\n",
    "            '-3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i == len(sent)-2:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i < len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        word3 = sent[i+3][0]\n",
    "        postag3 = sent[i+3][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "            '+3:word.lower()': word3.lower(),\n",
    "            '+3:word.istitle()': word3.istitle(),\n",
    "            '+3:word.isupper()': word3.isupper(),\n",
    "            '+3:postag': postag3,\n",
    "            '+3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features_3words(sent):\n",
    "    return [word2features_custom_3words(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# extract features and labels of sets\n",
    "X_train = [sent2features_3words(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_3words(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_3words(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18781321926080463\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.500     0.015     0.029        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.151     0.056     0.082       142\n",
      "I-creative-work      0.183     0.138     0.157       218\n",
      "        B-group      0.000     0.000     0.000       165\n",
      "        I-group      0.000     0.000     0.000        70\n",
      "     B-location      0.359     0.153     0.215       150\n",
      "     I-location      0.280     0.074     0.118        94\n",
      "       B-person      0.435     0.361     0.395       429\n",
      "       I-person      0.390     0.298     0.338       131\n",
      "      B-product      0.150     0.047     0.072       127\n",
      "      I-product      0.180     0.071     0.102       126\n",
      "\n",
      "      micro avg      0.324     0.160     0.214      1740\n",
      "      macro avg      0.219     0.101     0.126      1740\n",
      "   weighted avg      0.261     0.160     0.188      1740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)\n",
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Combination of additions of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14242344432653975\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.000     0.000     0.000        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.278     0.035     0.062       142\n",
      "I-creative-work      0.270     0.046     0.078       218\n",
      "        B-group      0.500     0.036     0.068       165\n",
      "        I-group      0.400     0.086     0.141        70\n",
      "     B-location      0.390     0.213     0.276       150\n",
      "     I-location      0.250     0.074     0.115        94\n",
      "       B-person      0.535     0.142     0.225       429\n",
      "       I-person      0.485     0.244     0.325       131\n",
      "      B-product      0.500     0.008     0.016       127\n",
      "      I-product      0.800     0.032     0.061       126\n",
      "\n",
      "      micro avg      0.430     0.094     0.155      1740\n",
      "      macro avg      0.367     0.076     0.114      1740\n",
      "   weighted avg      0.430     0.094     0.142      1740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "def word2features_custom_comb(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.ispunctuation()': 1 if word.lower() in string.punctuation else 0,\n",
    "        'word.stem()': stemmer.stem(word.lower()),\n",
    "        'word.isstopword()': 1 if word.lower() in stop_words else 0,\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i == 1:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '-1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '-1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '-1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '-1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:word.ispunctuation()': 1 if word2.lower() in string.punctuation else 0,\n",
    "            '-2:word.stem()': stemmer.stem(word2.lower()),\n",
    "            '-2:word.isstopword()': 1 if word2.lower() in stop_words else 0,\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i > 2:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word2 = sent[i-2][0]\n",
    "        postag2 = sent[i-2][1]\n",
    "        word3 = sent[i-3][0]\n",
    "        postag3 = sent[i-3][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '-1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '-1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:word.ispunctuation()': 1 if word2.lower() in string.punctuation else 0,\n",
    "            '-2:word.stem()': stemmer.stem(word2.lower()),\n",
    "            '-2:word.isstopword()': 1 if word2.lower() in stop_words else 0,\n",
    "            '-2:postag': postag2,\n",
    "            '-2:postag[:2]': postag2[:2],\n",
    "            '-3:word.lower()': word3.lower(),\n",
    "            '-3:word.istitle()': word3.istitle(),\n",
    "            '-3:word.isupper()': word3.isupper(),\n",
    "            '-3:word.ispunctuation()': 1 if word3.lower() in string.punctuation else 0,\n",
    "            '-3:word.stem()': stemmer.stem(word3.lower()),\n",
    "            '-3:word.isstopword()': 1 if word3.lower() in stop_words else 0,\n",
    "            '-3:postag': postag3,\n",
    "            '-3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i == len(sent)-2:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '+1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '+1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    elif i == len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '+1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '+1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:word.ispunctuation()': 1 if word2.lower() in string.punctuation else 0,\n",
    "            '+2:word.stem()': stemmer.stem(word2.lower()),\n",
    "            '+2:word.isstopword()': 1 if word2.lower() in stop_words else 0,\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    elif i < len(sent)-3:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        word3 = sent[i+3][0]\n",
    "        postag3 = sent[i+3][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.ispunctuation()': 1 if word1.lower() in string.punctuation else 0,\n",
    "            '+1:word.stem()': stemmer.stem(word1.lower()),\n",
    "            '+1:word.isstopword()': 1 if word1.lower() in stop_words else 0,\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:word.ispunctuation()': 1 if word2.lower() in string.punctuation else 0,\n",
    "            '+2:word.stem()': stemmer.stem(word2.lower()),\n",
    "            '+2:word.isstopword()': 1 if word2.lower() in stop_words else 0,\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "            '+3:word.lower()': word3.lower(),\n",
    "            '+3:word.istitle()': word3.istitle(),\n",
    "            '+3:word.isupper()': word3.isupper(),\n",
    "            '+3:word.ispunctuation()': 1 if word3.lower() in string.punctuation else 0,\n",
    "            '+3:word.stem()': stemmer.stem(word3.lower()),\n",
    "            '+3:word.isstopword()': 1 if word3.lower() in stop_words else 0,\n",
    "            '+3:postag': postag3,\n",
    "            '+3:postag[:2]': postag3[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features_comb(sent):\n",
    "    return [word2features_custom_comb(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# extract features and labels of sets\n",
    "X_train = [sent2features_comb(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features_comb(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_dev = [sent2features_comb(s) for s in dev_sents]\n",
    "y_dev = [sent2labels(s) for s in dev_sents]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# ignore entities labelled with 'Other'\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# prediction\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# F1-score\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19723798395691833\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      1.000     0.015     0.030        66\n",
      "  I-corporation      0.000     0.000     0.000        22\n",
      "B-creative-work      0.138     0.056     0.080       142\n",
      "I-creative-work      0.177     0.147     0.160       218\n",
      "        B-group      0.250     0.006     0.012       165\n",
      "        I-group      0.500     0.043     0.079        70\n",
      "     B-location      0.438     0.187     0.262       150\n",
      "     I-location      0.280     0.074     0.118        94\n",
      "       B-person      0.464     0.357     0.403       429\n",
      "       I-person      0.398     0.282     0.330       131\n",
      "      B-product      0.130     0.047     0.069       127\n",
      "      I-product      0.145     0.071     0.096       126\n",
      "\n",
      "      micro avg      0.328     0.164     0.218      1740\n",
      "      macro avg      0.327     0.107     0.137      1740\n",
      "   weighted avg      0.332     0.164     0.197      1740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Software\\AboutPrograming\\Anaconda3\\envs\\lower_ver\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer,\n",
    "                        random_state=123)\n",
    "rs.fit(X_dev, y_dev)\n",
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "# cls-report\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63ca0c8d3a239235585b09f22bd374cae13a775a92515e346cda6a4d44a7b14d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
