{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>1.1 Overview</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files/documents:  11314\n",
      "Number of targets/categories:  20\n"
     ]
    }
   ],
   "source": [
    "# Question 1.1. able to addresses all 20 categories.\n",
    "# extract dataset\n",
    "twenty_train = fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=123)\n",
    "twenty_test = fetch_20newsgroups(data_home=None, subset='test', categories=None, shuffle=True, random_state=321)\n",
    "\n",
    "\n",
    "# printing overview\n",
    "print('Number of files/documents: ', len(twenty_train.data))\n",
    "print('Number of targets/categories: ', len(twenty_train.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>1.2.1 Na√Øve Bayes with three types of feature (counts, tf, tfidf)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2. using three classifiers/types of feature on this multi-class classification task with four distinct paramerters.\n",
    "\n",
    "dict_results = dict()\n",
    "\n",
    "def Naive_bayes(train, test, lowercase=True, stopwords=None, ngram=(1,1), analyzer='word', max_features=None, print_report=False):\n",
    "\n",
    "    lst_results_train = []\n",
    "    lst_results_test = []\n",
    "    \n",
    "    # (1) feature: counts\n",
    "    NB_clf_counts = Pipeline([\n",
    "        (\"vect\", CountVectorizer(lowercase=lowercase, stop_words=stopwords, ngram_range=ngram, analyzer=analyzer, max_features=max_features)), \n",
    "        (\"clf\", MultinomialNB())\n",
    "        ])\n",
    "    NB_clf_counts.fit(train.data, train.target)\n",
    "    train_pred = NB_clf_counts.predict(train.data)\n",
    "    test_pred = NB_clf_counts.predict(test.data)\n",
    "\n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "    \n",
    "    # get results in detail\n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'counts')\n",
    "        report(test, test_pred, 'test', 'counts')\n",
    "\n",
    "    # (2) feature: tf\n",
    "    NB_clf_tf = Pipeline([\n",
    "        (\"vect\", CountVectorizer(lowercase=lowercase, stop_words=stopwords, ngram_range=ngram, analyzer=analyzer, max_features=max_features)), \n",
    "        ('tf',TfidfTransformer(use_idf=False)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "        ])\n",
    "    NB_clf_tf.fit(train.data, train.target)\n",
    "    train_pred = NB_clf_tf.predict(train.data)\n",
    "    test_pred = NB_clf_tf.predict(test.data)\n",
    "\n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "    \n",
    "    # get results in detail\n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'tf')\n",
    "        report(test, test_pred, 'test', 'tf')\n",
    "\n",
    "    # (3) feature: tf-idf\n",
    "    NB_clf_tfidf = Pipeline([\n",
    "        (\"vect\", CountVectorizer(lowercase=lowercase, stop_words=stopwords, ngram_range=ngram, analyzer=analyzer, max_features=max_features)), \n",
    "        ('tf',TfidfTransformer(use_idf=True)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "        ])\n",
    "    NB_clf_tfidf.fit(train.data, train.target)\n",
    "    train_pred = NB_clf_tfidf.predict(train.data)\n",
    "    test_pred = NB_clf_tfidf.predict(test.data)\n",
    "\n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    # get results in detail\n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'tfidf')\n",
    "        report(test, test_pred, 'test', 'tfidf')\n",
    "    \n",
    "    dict_results['NB_train'] = lst_results_train\n",
    "    dict_results['NB_test'] = lst_results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>1.2.2 Support Vector Machine with three types of feature (counts, tf, tfidf) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(train, test, print_report = False):\n",
    "    \n",
    "    lst_results_train = []\n",
    "    lst_results_test = []\n",
    "\n",
    "    # (1) feature: counts\n",
    "    SVM_clf_counts = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        (\"clf\", SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=789,\n",
    "                          max_iter=5, tol=None))\n",
    "        ])\n",
    "    SVM_clf_counts.fit(train.data, train.target)\n",
    "    train_pred = SVM_clf_counts.predict(train.data)\n",
    "    test_pred = SVM_clf_counts.predict(test.data)\n",
    "    \n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "    \n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'counts')\n",
    "        report(test, test_pred, 'test', 'counts')\n",
    "\n",
    "    \n",
    "    # (2) feature: tf\n",
    "    SVM_clf_tf = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        ('tf',TfidfTransformer(use_idf=False)),\n",
    "        (\"clf\", SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=789,\n",
    "                          max_iter=5, tol=None))\n",
    "        ])\n",
    "    SVM_clf_tf.fit(train.data, train.target)\n",
    "    train_pred = SVM_clf_tf.predict(train.data)\n",
    "    test_pred = SVM_clf_tf.predict(test.data)\n",
    "    \n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    \n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'tf')\n",
    "        report(test, test_pred, 'test', 'tf')\n",
    "\n",
    "    # (3) feature: tf-idf\n",
    "    SVM_clf_tfidf = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        ('tf',TfidfTransformer(use_idf=True)),\n",
    "        (\"clf\", SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=789,\n",
    "                          max_iter=5, tol=None))\n",
    "        ])\n",
    "    SVM_clf_tfidf.fit(train.data, train.target)\n",
    "    train_pred = SVM_clf_tfidf.predict(train.data)\n",
    "    test_pred = SVM_clf_tfidf.predict(test.data)\n",
    "    \n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'tfidf')\n",
    "        report(test, test_pred, 'test', 'tfidf')\n",
    "    \n",
    "    dict_results['SVM_train'] = lst_results_train\n",
    "    dict_results['SVM_test'] = lst_results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>1.2.3 RandomForest with three types of feature (counts, tf, tfidf)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(train, test, print_report=False):\n",
    "\n",
    "    lst_results_train = []\n",
    "    lst_results_test = []\n",
    "    \n",
    "    # (1) feature: counts\n",
    "    RF_clf_counts = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        (\"clf\",RandomForestClassifier())\n",
    "        ])\n",
    "    RF_clf_counts.fit(train.data, train.target)\n",
    "    train_pred = RF_clf_counts.predict(train.data)\n",
    "    test_pred = RF_clf_counts.predict(test.data)\n",
    "\n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    if print_report == True:\n",
    "            report(train, train_pred, 'train', 'counts')\n",
    "            report(test, test_pred, 'test', 'counts')\n",
    "\n",
    "    # (2) feature: tf\n",
    "    RF_clf_tf = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        ('tf',TfidfTransformer(use_idf=False)),\n",
    "        (\"clf\",RandomForestClassifier())\n",
    "        ])\n",
    "    RF_clf_tf.fit(train.data, train.target)\n",
    "    train_pred = RF_clf_tf.predict(train.data)\n",
    "    test_pred = RF_clf_tf.predict(test.data)\n",
    "\n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    if print_report == True:\n",
    "        report(train, train_pred, 'train', 'tf')\n",
    "        report(test, test_pred, 'test', 'tf')\n",
    "\n",
    "    # (3) feature: tf-idf\n",
    "    RF_clf_counts = Pipeline([\n",
    "        (\"vect\", CountVectorizer()), \n",
    "        ('tf',TfidfTransformer(use_idf=True)),\n",
    "        (\"clf\",RandomForestClassifier())\n",
    "        ])\n",
    "    RF_clf_counts.fit(train.data, train.target)\n",
    "    train_pred = RF_clf_counts.predict(train.data)\n",
    "    test_pred = RF_clf_counts.predict(test.data)\n",
    "    \n",
    "    # get scores\n",
    "    tr, tst = scores(train.target, train_pred, test.target, test_pred)\n",
    "    lst_results_train.append(tr)\n",
    "    lst_results_test.append(tst)\n",
    "\n",
    "    if print_report == True:\n",
    "            report(train, train_pred, 'train', 'tfidf')\n",
    "            report(test, test_pred, 'test', 'tfidf')\n",
    "\n",
    "\n",
    "    dict_results['RF_train'] = lst_results_train\n",
    "    dict_results['RF_test'] = lst_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(label_train, pred_train, label_test, pred_test):\n",
    "\n",
    "    # train\n",
    "    acc_tr = np.mean(pred_train == label_train)\n",
    "    f1_tr = f1_score(label_train, pred_train, average='macro')\n",
    "    pr_tr = precision_score(label_train, pred_train, average='macro')\n",
    "    recall_tr = recall_score(label_train, pred_train,  average='macro')\n",
    "\n",
    "    # test\n",
    "    acc_tst = np.mean(pred_test == label_test)\n",
    "    f1_tst = f1_score(label_test, pred_test, average='macro')\n",
    "    pr_tst = precision_score(label_test, pred_test, average='macro')\n",
    "    recall_tst = recall_score(label_test, pred_test,  average='macro')\n",
    "    return [acc_tr, f1_tr, pr_tr, recall_tr], [acc_tst, f1_tst, pr_tst, recall_tst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Score function (ACC, F1, RECALL, PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2.4 score function\n",
    "def report(dataset, pred, data_type, feature_type):\n",
    "    # clf_results_report\n",
    "    print(data_type, feature_type)\n",
    "    print(metrics.classification_report(dataset.target, pred, target_names=dataset.target_names))\n",
    "    # clf_results_confusion_matrix\n",
    "    # plt.figure(figsize=(20,25))\n",
    "    # cm = confusion_matrix(dataset.target, pred)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset.target_names)\n",
    "    # disp.plot()\n",
    "    return metrics.classification_report(dataset.target, pred, target_names=dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> 1.2 Results_Table </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Accuracy\n",
      "Train:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.924518  0.982941      0.999912\n",
      "tf         0.843910  0.916210      0.999912\n",
      "tf-idf     0.932650  0.965353      0.999912\n",
      "\n",
      "Test:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.772836  0.756240      0.766729\n",
      "tf         0.705258  0.774960      0.756771\n",
      "tf-idf     0.773898  0.823686      0.757833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# acc (train)\n",
    "Naive_bayes(twenty_train, twenty_test)\n",
    "SVM(twenty_train, twenty_test)\n",
    "RandomForest(twenty_train, twenty_test)\n",
    "\n",
    "acc_nb = [item[0] for item in dict_results['NB_train']]\n",
    "acc_svm = [item[0] for item in dict_results['SVM_train']]\n",
    "acc_rf = [item[0] for item in dict_results['RF_train']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': acc_nb, 'SVM': acc_svm, 'RandomForest': acc_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('>>>Accuracy')\n",
    "print('Train:')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# acc (test)\n",
    "acc_nb = [item[0] for item in dict_results['NB_test']]\n",
    "acc_svm = [item[0] for item in dict_results['SVM_test']]\n",
    "acc_rf = [item[0] for item in dict_results['RF_test']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': acc_nb, 'SVM': acc_svm, 'RandomForest': acc_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('Test:')\n",
    "print(df)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>F1-score\n",
      "Train:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.910492  0.981577      0.999916\n",
      "tf         0.811418  0.913249      0.999916\n",
      "tf-idf     0.919829  0.962300      0.999916\n",
      "\n",
      "Test:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.745098  0.744843      0.755293\n",
      "tf         0.672783  0.762184      0.743052\n",
      "tf-idf     0.755754  0.810701      0.750656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score (train)\n",
    "Naive_bayes(twenty_train, twenty_test)\n",
    "SVM(twenty_train, twenty_test)\n",
    "RandomForest(twenty_train, twenty_test)\n",
    "\n",
    "f1_nb = [item[1] for item in dict_results['NB_train']]\n",
    "f1_svm = [item[1] for item in dict_results['SVM_train']]\n",
    "f1_rf = [item[1] for item in dict_results['RF_train']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': f1_nb, 'SVM': f1_svm, 'RandomForest': f1_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('>>>F1-score')\n",
    "print('Train:')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# f1-score (test)\n",
    "f1_nb = [item[1] for item in dict_results['NB_test']]\n",
    "f1_svm = [item[1] for item in dict_results['SVM_test']]\n",
    "f1_rf = [item[1] for item in dict_results['RF_test']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': f1_nb, 'SVM': f1_svm, 'RandomForest': f1_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('Test:')\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Precision\n",
      "Train:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.934817  0.982938      0.999916\n",
      "tf         0.892994  0.921196      0.999916\n",
      "tf-idf     0.945940  0.967068      0.999916\n",
      "\n",
      "Test:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.762163  0.758820      0.774657\n",
      "tf         0.792431  0.774403      0.762383\n",
      "tf-idf     0.825531  0.826490      0.766009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# precision (train)\n",
    "Naive_bayes(twenty_train, twenty_test)\n",
    "SVM(twenty_train, twenty_test)\n",
    "RandomForest(twenty_train, twenty_test)\n",
    "\n",
    "pr_nb = [item[2] for item in dict_results['NB_train']]\n",
    "pr_svm = [item[2] for item in dict_results['SVM_train']]\n",
    "pr_rf = [item[2] for item in dict_results['RF_train']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': pr_nb, 'SVM': pr_svm, 'RandomForest': pr_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('>>>Precision')\n",
    "print('Train:')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# precision (test)\n",
    "pr_nb = [item[2] for item in dict_results['NB_test']]\n",
    "pr_svm = [item[2] for item in dict_results['SVM_test']]\n",
    "pr_rf = [item[2] for item in dict_results['RF_test']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': pr_nb, 'SVM': pr_svm, 'RandomForest': pr_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('Test:')\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Recall\n",
      "Train:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.922883  0.980575      0.999916\n",
      "tf         0.819943  0.910769      0.999916\n",
      "tf-idf     0.919103  0.960484      0.999916\n",
      "\n",
      "Test:\n",
      "        Naive Bayes       SVM  RandomForest\n",
      "counts     0.763646  0.745118      0.754594\n",
      "tf         0.682195  0.763804      0.745149\n",
      "tf-idf     0.756525  0.812133      0.745164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recall (train)\n",
    "Naive_bayes(twenty_train, twenty_test)\n",
    "SVM(twenty_train, twenty_test)\n",
    "RandomForest(twenty_train, twenty_test)\n",
    "\n",
    "recall_nb = [item[3] for item in dict_results['NB_train']]\n",
    "recall_svm = [item[3] for item in dict_results['SVM_train']]\n",
    "recall_rf = [item[3] for item in dict_results['RF_train']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': recall_nb, 'SVM': recall_svm, 'RandomForest': recall_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('>>>Recall')\n",
    "print('Train:')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# recall (test)\n",
    "recall_nb = [item[3] for item in dict_results['NB_test']]\n",
    "recall_svm = [item[3] for item in dict_results['SVM_test']]\n",
    "recall_rf = [item[3] for item in dict_results['RF_test']]\n",
    "\n",
    "df = pd.DataFrame({'Naive Bayes': recall_nb, 'SVM': recall_svm, 'RandomForest': recall_rf}, index=['counts', 'tf', 'tf-idf'])\n",
    "print('Test:')\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>1.2 Classification report </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.93      0.98      0.95       480\n",
      "           comp.graphics       0.85      0.97      0.90       584\n",
      " comp.os.ms-windows.misc       0.98      0.14      0.25       591\n",
      "comp.sys.ibm.pc.hardware       0.70      0.96      0.81       590\n",
      "   comp.sys.mac.hardware       0.95      0.98      0.97       578\n",
      "          comp.windows.x       0.80      0.98      0.88       593\n",
      "            misc.forsale       0.97      0.85      0.91       585\n",
      "               rec.autos       0.96      0.98      0.97       594\n",
      "         rec.motorcycles       0.99      0.98      0.99       598\n",
      "      rec.sport.baseball       1.00      0.99      0.99       597\n",
      "        rec.sport.hockey       0.98      0.99      0.98       600\n",
      "               sci.crypt       0.92      0.99      0.95       595\n",
      "         sci.electronics       0.95      0.96      0.96       591\n",
      "                 sci.med       0.98      0.98      0.98       594\n",
      "               sci.space       0.97      1.00      0.99       593\n",
      "  soc.religion.christian       0.92      0.99      0.95       599\n",
      "      talk.politics.guns       0.95      0.99      0.97       546\n",
      "   talk.politics.mideast       0.96      0.99      0.97       564\n",
      "      talk.politics.misc       0.93      0.97      0.95       465\n",
      "      talk.religion.misc       0.99      0.77      0.87       377\n",
      "\n",
      "                accuracy                           0.92     11314\n",
      "               macro avg       0.93      0.92      0.91     11314\n",
      "            weighted avg       0.93      0.92      0.91     11314\n",
      "\n",
      "test counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.77      0.78       319\n",
      "           comp.graphics       0.67      0.74      0.70       389\n",
      " comp.os.ms-windows.misc       0.20      0.00      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.56      0.77      0.65       392\n",
      "   comp.sys.mac.hardware       0.84      0.75      0.79       385\n",
      "          comp.windows.x       0.65      0.84      0.73       395\n",
      "            misc.forsale       0.93      0.65      0.77       390\n",
      "               rec.autos       0.87      0.91      0.89       396\n",
      "         rec.motorcycles       0.96      0.92      0.94       398\n",
      "      rec.sport.baseball       0.96      0.87      0.91       397\n",
      "        rec.sport.hockey       0.93      0.96      0.95       399\n",
      "               sci.crypt       0.67      0.95      0.78       396\n",
      "         sci.electronics       0.79      0.66      0.72       393\n",
      "                 sci.med       0.87      0.82      0.85       396\n",
      "               sci.space       0.83      0.89      0.86       394\n",
      "  soc.religion.christian       0.70      0.96      0.81       398\n",
      "      talk.politics.guns       0.69      0.91      0.79       364\n",
      "   talk.politics.mideast       0.85      0.94      0.89       376\n",
      "      talk.politics.misc       0.58      0.63      0.60       310\n",
      "      talk.religion.misc       0.89      0.33      0.49       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.76      0.76      0.75      7532\n",
      "            weighted avg       0.76      0.77      0.75      7532\n",
      "\n",
      "train tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.91      0.53      0.67       480\n",
      "           comp.graphics       0.90      0.79      0.84       584\n",
      " comp.os.ms-windows.misc       0.91      0.89      0.90       591\n",
      "comp.sys.ibm.pc.hardware       0.80      0.90      0.85       590\n",
      "   comp.sys.mac.hardware       0.98      0.89      0.93       578\n",
      "          comp.windows.x       0.97      0.89      0.93       593\n",
      "            misc.forsale       0.94      0.78      0.85       585\n",
      "               rec.autos       0.85      0.97      0.90       594\n",
      "         rec.motorcycles       0.93      0.96      0.95       598\n",
      "      rec.sport.baseball       0.96      0.96      0.96       597\n",
      "        rec.sport.hockey       0.94      0.97      0.96       600\n",
      "               sci.crypt       0.67      0.98      0.80       595\n",
      "         sci.electronics       0.95      0.85      0.90       591\n",
      "                 sci.med       0.94      0.94      0.94       594\n",
      "               sci.space       0.92      0.96      0.94       593\n",
      "  soc.religion.christian       0.44      0.99      0.61       599\n",
      "      talk.politics.guns       0.87      0.95      0.90       546\n",
      "   talk.politics.mideast       0.97      0.91      0.94       564\n",
      "      talk.politics.misc       1.00      0.28      0.43       465\n",
      "      talk.religion.misc       1.00      0.01      0.02       377\n",
      "\n",
      "                accuracy                           0.84     11314\n",
      "               macro avg       0.89      0.82      0.81     11314\n",
      "            weighted avg       0.89      0.84      0.83     11314\n",
      "\n",
      "test tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.24      0.37       319\n",
      "           comp.graphics       0.71      0.60      0.65       389\n",
      " comp.os.ms-windows.misc       0.79      0.65      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.75      0.69       392\n",
      "   comp.sys.mac.hardware       0.86      0.68      0.76       385\n",
      "          comp.windows.x       0.88      0.68      0.77       395\n",
      "            misc.forsale       0.90      0.72      0.80       390\n",
      "               rec.autos       0.71      0.92      0.80       396\n",
      "         rec.motorcycles       0.84      0.91      0.87       398\n",
      "      rec.sport.baseball       0.86      0.85      0.86       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.52      0.96      0.67       396\n",
      "         sci.electronics       0.78      0.52      0.63       393\n",
      "                 sci.med       0.82      0.76      0.79       396\n",
      "               sci.space       0.83      0.81      0.82       394\n",
      "  soc.religion.christian       0.34      0.98      0.51       398\n",
      "      talk.politics.guns       0.66      0.80      0.73       364\n",
      "   talk.politics.mideast       0.96      0.72      0.82       376\n",
      "      talk.politics.misc       1.00      0.17      0.29       310\n",
      "      talk.religion.misc       1.00      0.01      0.02       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.79      0.68      0.67      7532\n",
      "            weighted avg       0.79      0.71      0.69      7532\n",
      "\n",
      "train tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.83      0.87       480\n",
      "           comp.graphics       0.98      0.93      0.95       584\n",
      " comp.os.ms-windows.misc       0.97      0.95      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.90      0.96      0.93       590\n",
      "   comp.sys.mac.hardware       0.99      0.97      0.98       578\n",
      "          comp.windows.x       0.99      0.96      0.97       593\n",
      "            misc.forsale       0.97      0.86      0.91       585\n",
      "               rec.autos       0.96      0.99      0.97       594\n",
      "         rec.motorcycles       0.99      0.98      0.99       598\n",
      "      rec.sport.baseball       0.99      0.98      0.99       597\n",
      "        rec.sport.hockey       0.97      0.99      0.98       600\n",
      "               sci.crypt       0.89      0.99      0.94       595\n",
      "         sci.electronics       0.98      0.94      0.96       591\n",
      "                 sci.med       1.00      0.96      0.98       594\n",
      "               sci.space       0.96      0.99      0.98       593\n",
      "  soc.religion.christian       0.63      1.00      0.77       599\n",
      "      talk.politics.guns       0.89      0.99      0.94       546\n",
      "   talk.politics.mideast       0.97      0.98      0.97       564\n",
      "      talk.politics.misc       0.99      0.83      0.90       465\n",
      "      talk.religion.misc       0.99      0.29      0.45       377\n",
      "\n",
      "                accuracy                           0.93     11314\n",
      "               macro avg       0.95      0.92      0.92     11314\n",
      "            weighted avg       0.94      0.93      0.93     11314\n",
      "\n",
      "test tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Naive_bayes(twenty_train, twenty_test, print_report=True) # classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.99      0.94      0.96       480\n",
      "           comp.graphics       0.96      0.99      0.97       584\n",
      " comp.os.ms-windows.misc       0.99      0.98      0.99       591\n",
      "comp.sys.ibm.pc.hardware       0.99      0.97      0.98       590\n",
      "   comp.sys.mac.hardware       0.99      0.99      0.99       578\n",
      "          comp.windows.x       1.00      1.00      1.00       593\n",
      "            misc.forsale       0.98      0.99      0.99       585\n",
      "               rec.autos       0.99      1.00      0.99       594\n",
      "         rec.motorcycles       0.99      0.99      0.99       598\n",
      "      rec.sport.baseball       0.98      1.00      0.99       597\n",
      "        rec.sport.hockey       0.99      1.00      1.00       600\n",
      "               sci.crypt       0.99      1.00      0.99       595\n",
      "         sci.electronics       0.95      0.99      0.97       591\n",
      "                 sci.med       0.98      0.99      0.99       594\n",
      "               sci.space       0.99      1.00      1.00       593\n",
      "  soc.religion.christian       0.95      0.98      0.97       599\n",
      "      talk.politics.guns       0.99      0.97      0.98       546\n",
      "   talk.politics.mideast       0.99      0.99      0.99       564\n",
      "      talk.politics.misc       0.99      0.95      0.97       465\n",
      "      talk.religion.misc       0.96      0.90      0.93       377\n",
      "\n",
      "                accuracy                           0.98     11314\n",
      "               macro avg       0.98      0.98      0.98     11314\n",
      "            weighted avg       0.98      0.98      0.98     11314\n",
      "\n",
      "test counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.54      0.64       319\n",
      "           comp.graphics       0.52      0.77      0.62       389\n",
      " comp.os.ms-windows.misc       0.75      0.54      0.63       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.60      0.63       392\n",
      "   comp.sys.mac.hardware       0.69      0.80      0.74       385\n",
      "          comp.windows.x       0.78      0.68      0.73       395\n",
      "            misc.forsale       0.82      0.79      0.80       390\n",
      "               rec.autos       0.75      0.86      0.80       396\n",
      "         rec.motorcycles       0.85      0.89      0.87       398\n",
      "      rec.sport.baseball       0.80      0.87      0.84       397\n",
      "        rec.sport.hockey       0.85      0.94      0.89       399\n",
      "               sci.crypt       0.87      0.87      0.87       396\n",
      "         sci.electronics       0.67      0.66      0.66       393\n",
      "                 sci.med       0.78      0.79      0.78       396\n",
      "               sci.space       0.83      0.90      0.86       394\n",
      "  soc.religion.christian       0.76      0.89      0.82       398\n",
      "      talk.politics.guns       0.71      0.80      0.75       364\n",
      "   talk.politics.mideast       0.92      0.78      0.84       376\n",
      "      talk.politics.misc       0.80      0.51      0.62       310\n",
      "      talk.religion.misc       0.56      0.41      0.47       251\n",
      "\n",
      "                accuracy                           0.76      7532\n",
      "               macro avg       0.76      0.75      0.74      7532\n",
      "            weighted avg       0.76      0.76      0.75      7532\n",
      "\n",
      "train tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.94      0.86      0.90       480\n",
      "           comp.graphics       0.92      0.86      0.89       584\n",
      " comp.os.ms-windows.misc       0.82      0.93      0.87       591\n",
      "comp.sys.ibm.pc.hardware       0.83      0.87      0.85       590\n",
      "   comp.sys.mac.hardware       0.98      0.85      0.91       578\n",
      "          comp.windows.x       0.96      0.89      0.93       593\n",
      "            misc.forsale       0.83      0.91      0.87       585\n",
      "               rec.autos       0.93      0.94      0.93       594\n",
      "         rec.motorcycles       0.98      0.94      0.96       598\n",
      "      rec.sport.baseball       0.97      0.94      0.96       597\n",
      "        rec.sport.hockey       0.93      0.98      0.95       600\n",
      "               sci.crypt       0.93      0.97      0.95       595\n",
      "         sci.electronics       0.92      0.88      0.90       591\n",
      "                 sci.med       0.98      0.95      0.96       594\n",
      "               sci.space       0.90      0.98      0.94       593\n",
      "  soc.religion.christian       0.80      0.97      0.88       599\n",
      "      talk.politics.guns       0.97      0.93      0.95       546\n",
      "   talk.politics.mideast       0.96      0.98      0.97       564\n",
      "      talk.politics.misc       0.94      0.93      0.93       465\n",
      "      talk.religion.misc       0.93      0.64      0.76       377\n",
      "\n",
      "                accuracy                           0.92     11314\n",
      "               macro avg       0.92      0.91      0.91     11314\n",
      "            weighted avg       0.92      0.92      0.92     11314\n",
      "\n",
      "test tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.60      0.65       319\n",
      "           comp.graphics       0.73      0.66      0.69       389\n",
      " comp.os.ms-windows.misc       0.66      0.75      0.70       394\n",
      "comp.sys.ibm.pc.hardware       0.64      0.69      0.67       392\n",
      "   comp.sys.mac.hardware       0.86      0.69      0.76       385\n",
      "          comp.windows.x       0.80      0.68      0.73       395\n",
      "            misc.forsale       0.73      0.90      0.81       390\n",
      "               rec.autos       0.84      0.85      0.85       396\n",
      "         rec.motorcycles       0.89      0.92      0.91       398\n",
      "      rec.sport.baseball       0.86      0.85      0.86       397\n",
      "        rec.sport.hockey       0.84      0.97      0.90       399\n",
      "               sci.crypt       0.82      0.93      0.87       396\n",
      "         sci.electronics       0.71      0.58      0.64       393\n",
      "                 sci.med       0.86      0.72      0.79       396\n",
      "               sci.space       0.78      0.92      0.84       394\n",
      "  soc.religion.christian       0.70      0.95      0.80       398\n",
      "      talk.politics.guns       0.74      0.79      0.76       364\n",
      "   talk.politics.mideast       0.91      0.85      0.88       376\n",
      "      talk.politics.misc       0.70      0.58      0.63       310\n",
      "      talk.religion.misc       0.71      0.38      0.50       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.77      0.76      0.76      7532\n",
      "            weighted avg       0.78      0.77      0.77      7532\n",
      "\n",
      "train tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.95      0.95      0.95       480\n",
      "           comp.graphics       0.98      0.94      0.96       584\n",
      " comp.os.ms-windows.misc       0.94      0.97      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.94      0.94      0.94       590\n",
      "   comp.sys.mac.hardware       0.98      0.97      0.98       578\n",
      "          comp.windows.x       0.98      0.97      0.98       593\n",
      "            misc.forsale       0.93      0.96      0.95       585\n",
      "               rec.autos       0.98      0.98      0.98       594\n",
      "         rec.motorcycles       0.98      0.99      0.99       598\n",
      "      rec.sport.baseball       1.00      0.98      0.99       597\n",
      "        rec.sport.hockey       0.97      1.00      0.98       600\n",
      "               sci.crypt       0.98      1.00      0.99       595\n",
      "         sci.electronics       0.99      0.94      0.97       591\n",
      "                 sci.med       0.99      0.99      0.99       594\n",
      "               sci.space       0.96      1.00      0.98       593\n",
      "  soc.religion.christian       0.87      0.99      0.93       599\n",
      "      talk.politics.guns       0.96      0.99      0.97       546\n",
      "   talk.politics.mideast       0.97      1.00      0.98       564\n",
      "      talk.politics.misc       0.99      0.95      0.97       465\n",
      "      talk.religion.misc       0.99      0.71      0.83       377\n",
      "\n",
      "                accuracy                           0.97     11314\n",
      "               macro avg       0.97      0.96      0.96     11314\n",
      "            weighted avg       0.97      0.97      0.96     11314\n",
      "\n",
      "test tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.70      0.71       319\n",
      "           comp.graphics       0.80      0.71      0.75       389\n",
      " comp.os.ms-windows.misc       0.72      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.69      0.71       392\n",
      "   comp.sys.mac.hardware       0.83      0.82      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.89      0.87       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.94       398\n",
      "      rec.sport.baseball       0.90      0.90      0.90       397\n",
      "        rec.sport.hockey       0.87      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.89       396\n",
      "         sci.electronics       0.81      0.63      0.71       393\n",
      "                 sci.med       0.89      0.85      0.87       396\n",
      "               sci.space       0.85      0.96      0.90       394\n",
      "  soc.religion.christian       0.73      0.94      0.82       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.91      0.92      0.92       376\n",
      "      talk.politics.misc       0.87      0.57      0.69       310\n",
      "      talk.religion.misc       0.84      0.39      0.54       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM(twenty_train, twenty_test, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       1.00      1.00      1.00       480\n",
      "           comp.graphics       1.00      1.00      1.00       584\n",
      " comp.os.ms-windows.misc       1.00      1.00      1.00       591\n",
      "comp.sys.ibm.pc.hardware       1.00      1.00      1.00       590\n",
      "   comp.sys.mac.hardware       1.00      1.00      1.00       578\n",
      "          comp.windows.x       1.00      1.00      1.00       593\n",
      "            misc.forsale       1.00      1.00      1.00       585\n",
      "               rec.autos       1.00      1.00      1.00       594\n",
      "         rec.motorcycles       1.00      1.00      1.00       598\n",
      "      rec.sport.baseball       1.00      1.00      1.00       597\n",
      "        rec.sport.hockey       1.00      1.00      1.00       600\n",
      "               sci.crypt       1.00      1.00      1.00       595\n",
      "         sci.electronics       1.00      1.00      1.00       591\n",
      "                 sci.med       1.00      1.00      1.00       594\n",
      "               sci.space       1.00      1.00      1.00       593\n",
      "  soc.religion.christian       1.00      1.00      1.00       599\n",
      "      talk.politics.guns       1.00      1.00      1.00       546\n",
      "   talk.politics.mideast       1.00      1.00      1.00       564\n",
      "      talk.politics.misc       1.00      1.00      1.00       465\n",
      "      talk.religion.misc       1.00      1.00      1.00       377\n",
      "\n",
      "                accuracy                           1.00     11314\n",
      "               macro avg       1.00      1.00      1.00     11314\n",
      "            weighted avg       1.00      1.00      1.00     11314\n",
      "\n",
      "test counts\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.66      0.66       319\n",
      "           comp.graphics       0.57      0.73      0.64       389\n",
      " comp.os.ms-windows.misc       0.68      0.79      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.68      0.67      0.68       392\n",
      "   comp.sys.mac.hardware       0.75      0.79      0.77       385\n",
      "          comp.windows.x       0.78      0.72      0.75       395\n",
      "            misc.forsale       0.76      0.91      0.83       390\n",
      "               rec.autos       0.82      0.81      0.81       396\n",
      "         rec.motorcycles       0.92      0.89      0.91       398\n",
      "      rec.sport.baseball       0.80      0.91      0.85       397\n",
      "        rec.sport.hockey       0.91      0.92      0.92       399\n",
      "               sci.crypt       0.88      0.91      0.89       396\n",
      "         sci.electronics       0.70      0.50      0.58       393\n",
      "                 sci.med       0.85      0.68      0.75       396\n",
      "               sci.space       0.82      0.85      0.84       394\n",
      "  soc.religion.christian       0.69      0.93      0.79       398\n",
      "      talk.politics.guns       0.66      0.85      0.75       364\n",
      "   talk.politics.mideast       0.94      0.79      0.86       376\n",
      "      talk.politics.misc       0.88      0.49      0.63       310\n",
      "      talk.religion.misc       0.82      0.33      0.47       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.78      0.76      0.76      7532\n",
      "            weighted avg       0.78      0.77      0.76      7532\n",
      "\n",
      "train tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       1.00      1.00      1.00       480\n",
      "           comp.graphics       1.00      1.00      1.00       584\n",
      " comp.os.ms-windows.misc       1.00      1.00      1.00       591\n",
      "comp.sys.ibm.pc.hardware       1.00      1.00      1.00       590\n",
      "   comp.sys.mac.hardware       1.00      1.00      1.00       578\n",
      "          comp.windows.x       1.00      1.00      1.00       593\n",
      "            misc.forsale       1.00      1.00      1.00       585\n",
      "               rec.autos       1.00      1.00      1.00       594\n",
      "         rec.motorcycles       1.00      1.00      1.00       598\n",
      "      rec.sport.baseball       1.00      1.00      1.00       597\n",
      "        rec.sport.hockey       1.00      1.00      1.00       600\n",
      "               sci.crypt       1.00      1.00      1.00       595\n",
      "         sci.electronics       1.00      1.00      1.00       591\n",
      "                 sci.med       1.00      1.00      1.00       594\n",
      "               sci.space       1.00      1.00      1.00       593\n",
      "  soc.religion.christian       1.00      1.00      1.00       599\n",
      "      talk.politics.guns       1.00      1.00      1.00       546\n",
      "   talk.politics.mideast       1.00      1.00      1.00       564\n",
      "      talk.politics.misc       1.00      1.00      1.00       465\n",
      "      talk.religion.misc       1.00      1.00      1.00       377\n",
      "\n",
      "                accuracy                           1.00     11314\n",
      "               macro avg       1.00      1.00      1.00     11314\n",
      "            weighted avg       1.00      1.00      1.00     11314\n",
      "\n",
      "test tf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.70      0.62      0.66       319\n",
      "           comp.graphics       0.56      0.70      0.62       389\n",
      " comp.os.ms-windows.misc       0.67      0.75      0.70       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.65      0.65       392\n",
      "   comp.sys.mac.hardware       0.73      0.79      0.76       385\n",
      "          comp.windows.x       0.79      0.72      0.75       395\n",
      "            misc.forsale       0.72      0.92      0.81       390\n",
      "               rec.autos       0.82      0.79      0.80       396\n",
      "         rec.motorcycles       0.91      0.89      0.90       398\n",
      "      rec.sport.baseball       0.79      0.89      0.84       397\n",
      "        rec.sport.hockey       0.89      0.91      0.90       399\n",
      "               sci.crypt       0.87      0.91      0.89       396\n",
      "         sci.electronics       0.71      0.51      0.59       393\n",
      "                 sci.med       0.84      0.67      0.74       396\n",
      "               sci.space       0.81      0.89      0.85       394\n",
      "  soc.religion.christian       0.69      0.92      0.79       398\n",
      "      talk.politics.guns       0.64      0.85      0.73       364\n",
      "   talk.politics.mideast       0.93      0.79      0.85       376\n",
      "      talk.politics.misc       0.89      0.46      0.61       310\n",
      "      talk.religion.misc       0.71      0.30      0.42       251\n",
      "\n",
      "                accuracy                           0.76      7532\n",
      "               macro avg       0.77      0.75      0.74      7532\n",
      "            weighted avg       0.77      0.76      0.75      7532\n",
      "\n",
      "train tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       1.00      1.00      1.00       480\n",
      "           comp.graphics       1.00      1.00      1.00       584\n",
      " comp.os.ms-windows.misc       1.00      1.00      1.00       591\n",
      "comp.sys.ibm.pc.hardware       1.00      1.00      1.00       590\n",
      "   comp.sys.mac.hardware       1.00      1.00      1.00       578\n",
      "          comp.windows.x       1.00      1.00      1.00       593\n",
      "            misc.forsale       1.00      1.00      1.00       585\n",
      "               rec.autos       1.00      1.00      1.00       594\n",
      "         rec.motorcycles       1.00      1.00      1.00       598\n",
      "      rec.sport.baseball       1.00      1.00      1.00       597\n",
      "        rec.sport.hockey       1.00      1.00      1.00       600\n",
      "               sci.crypt       1.00      1.00      1.00       595\n",
      "         sci.electronics       1.00      1.00      1.00       591\n",
      "                 sci.med       1.00      1.00      1.00       594\n",
      "               sci.space       1.00      1.00      1.00       593\n",
      "  soc.religion.christian       1.00      1.00      1.00       599\n",
      "      talk.politics.guns       1.00      1.00      1.00       546\n",
      "   talk.politics.mideast       1.00      1.00      1.00       564\n",
      "      talk.politics.misc       1.00      1.00      1.00       465\n",
      "      talk.religion.misc       1.00      1.00      1.00       377\n",
      "\n",
      "                accuracy                           1.00     11314\n",
      "               macro avg       1.00      1.00      1.00     11314\n",
      "            weighted avg       1.00      1.00      1.00     11314\n",
      "\n",
      "test tfidf\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.71      0.62      0.66       319\n",
      "           comp.graphics       0.59      0.69      0.64       389\n",
      " comp.os.ms-windows.misc       0.67      0.77      0.72       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.67      0.67       392\n",
      "   comp.sys.mac.hardware       0.72      0.75      0.73       385\n",
      "          comp.windows.x       0.74      0.69      0.71       395\n",
      "            misc.forsale       0.73      0.91      0.81       390\n",
      "               rec.autos       0.80      0.82      0.81       396\n",
      "         rec.motorcycles       0.92      0.91      0.92       398\n",
      "      rec.sport.baseball       0.80      0.90      0.85       397\n",
      "        rec.sport.hockey       0.91      0.93      0.92       399\n",
      "               sci.crypt       0.88      0.92      0.90       396\n",
      "         sci.electronics       0.69      0.53      0.60       393\n",
      "                 sci.med       0.83      0.65      0.73       396\n",
      "               sci.space       0.82      0.88      0.85       394\n",
      "  soc.religion.christian       0.68      0.93      0.79       398\n",
      "      talk.politics.guns       0.66      0.87      0.75       364\n",
      "   talk.politics.mideast       0.94      0.78      0.85       376\n",
      "      talk.politics.misc       0.85      0.48      0.61       310\n",
      "      talk.religion.misc       0.80      0.32      0.46       251\n",
      "\n",
      "                accuracy                           0.76      7532\n",
      "               macro avg       0.77      0.75      0.75      7532\n",
      "            weighted avg       0.77      0.76      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest(twenty_train, twenty_test, print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> 1.4 Different values for four distinct parameters (lowercase, stop_words, analyzer, max_features) on Naive Bayes</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB_train</th>\n",
       "      <th>NB_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Counts</th>\n",
       "      <td>0.924518</td>\n",
       "      <td>0.772836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf</th>\n",
       "      <td>0.843910</td>\n",
       "      <td>0.705258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>0.932650</td>\n",
       "      <td>0.773898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NB_train   NB_test\n",
       "Counts  0.924518  0.772836\n",
       "tf      0.843910  0.705258\n",
       "tf-idf  0.932650  0.773898"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default\n",
    "acc = Naive_bayes(twenty_train, twenty_test)\n",
    "\n",
    "# print\n",
    "pd.DataFrame(acc, index=['Counts', 'tf', 'tf-idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowercase (True -> False)\n",
      "        Naive Bayes on train  Naive Bayes on test\n",
      "Counts              0.766994             0.766994\n",
      "tf                  0.692512             0.692512\n",
      "tf-idf              0.768986             0.768986\n"
     ]
    }
   ],
   "source": [
    "# lowercase\n",
    "Naive_bayes(twenty_train, twenty_test, lowercase=False)\n",
    "acc = [item[0] for item in dict_results['NB_train']]\n",
    "acc = [item[0] for item in dict_results['NB_test']]\n",
    "\n",
    "# print\n",
    "df = pd.DataFrame({'Naive Bayes on train': acc, 'Naive Bayes on test': acc}, index=['Counts', 'tf', 'tf-idf'])\n",
    "print('lowercase (True -> False)')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords (None -> 'english')\n",
      "        Naive Bayes on train  Naive Bayes on test\n",
      "Counts              0.802310             0.802310\n",
      "tf                  0.790361             0.790361\n",
      "tf-idf              0.816914             0.816914\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "Naive_bayes(twenty_train, twenty_test, stopwords='english')\n",
    "acc = [item[0] for item in dict_results['NB_train']]\n",
    "acc = [item[0] for item in dict_results['NB_test']]\n",
    "\n",
    "# print\n",
    "df = pd.DataFrame({'Naive Bayes on train': acc, 'Naive Bayes on test': acc}, index=['Counts', 'tf', 'tf-idf'])\n",
    "print('stopwords (None -> \\'english\\')')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram ( (1,1) -> (1,2) )\n",
      "        Naive Bayes on train  Naive Bayes on test\n",
      "Counts              0.739511             0.739511\n",
      "tf                  0.692910             0.692910\n",
      "tf-idf              0.765401             0.765401\n"
     ]
    }
   ],
   "source": [
    "# analyzer (in combination with ngram_range)\n",
    "Naive_bayes(twenty_train, twenty_test, analyzer='word', ngram=(1,2))\n",
    "acc = [item[0] for item in dict_results['NB_train']]\n",
    "acc = [item[0] for item in dict_results['NB_test']]\n",
    "\n",
    "# print\n",
    "df = pd.DataFrame({'Naive Bayes on train': acc, 'Naive Bayes on test': acc}, index=['Counts', 'tf', 'tf-idf'])\n",
    "print('ngram ( (1,1) -> (1,2) )')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features ( None -> 10000)\n",
      "        Naive Bayes on train  Naive Bayes on test\n",
      "Counts              0.772438             0.772438\n",
      "tf                  0.724509             0.724509\n",
      "tf-idf              0.793548             0.793548\n"
     ]
    }
   ],
   "source": [
    "# max_features\n",
    "Naive_bayes(twenty_train, twenty_test, max_features=10000)\n",
    "\n",
    "acc = [item[0] for item in dict_results['NB_train']]\n",
    "acc = [item[0] for item in dict_results['NB_test']]\n",
    "\n",
    "# print\n",
    "df = pd.DataFrame({'Naive Bayes on train': acc, 'Naive Bayes on test': acc}, index=['Counts', 'tf', 'tf-idf'])\n",
    "print('max_features ( None -> 10000)')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63ca0c8d3a239235585b09f22bd374cae13a775a92515e346cda6a4d44a7b14d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
