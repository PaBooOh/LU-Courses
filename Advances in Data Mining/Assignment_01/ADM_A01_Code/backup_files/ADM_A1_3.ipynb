{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isnan\n",
    "import joblib\n",
    "import numpy.ma as ma\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Threads(threading.Thread):\n",
    "    def __init__(self, threadID, k_fold_dataset, lr=0.005):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.k_fold_dataset = k_fold_dataset\n",
    "        self.lr = lr\n",
    "    \n",
    "    def run(self):\n",
    "        train_set = self.k_fold_dataset[self.threadID-1][0]\n",
    "        test_set = self.k_fold_dataset[self.threadID-1][1]\n",
    "        model = SVD(\n",
    "            self.threadID, \n",
    "            train_set, \n",
    "            test_set, \n",
    "            lr=self.lr)\n",
    "        model.training()\n",
    "\n",
    "# cv for User/Movie matrix only\n",
    "class CrossValidation():\n",
    "    def __init__(self, file_path, shuffle=True, normolize=False):\n",
    "        self.file_path = file_path\n",
    "        self.normolize = normolize\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def process_dataset(self):\n",
    "        ratings = pd.read_csv(\n",
    "            self.file_path,\n",
    "            sep='::',\n",
    "            engine='python',\n",
    "            header=None,\n",
    "            names=['UserID','MovieID','Rating','Timestamp'])\n",
    "\n",
    "        ratings = ratings.pivot(\n",
    "            index = 'UserID', \n",
    "            columns ='MovieID', \n",
    "            values = 'Rating')\n",
    "        return ratings\n",
    "    \n",
    "    def split(self, fold=5, all=False, save=False):\n",
    "\n",
    "        # process raw data\n",
    "        ratings = self.process_dataset()\n",
    "\n",
    "        # not folding but regarding whole dataset as train set\n",
    "        if all:\n",
    "            return ratings.to_numpy()\n",
    "        \n",
    "        dict_ratings_valid = dict()\n",
    "        lst_ratings_valid = []\n",
    "\n",
    "        \n",
    "        cols = ratings.columns.values.tolist()\n",
    "        for i, row in ratings.iterrows():\n",
    "            temp = []\n",
    "            for col in cols:\n",
    "                if isnan(row[col]) == False:\n",
    "                    temp.append([col, row[col]])\n",
    "            dict_ratings_valid[i] = temp\n",
    "        \n",
    "        print(dict_ratings_valid[2])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "def load_dataset(train_set_path, test_set_path):\n",
    "        return joblib.load(train_set_path), joblib.load(test_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_dataset('train_set_2', 'test_set_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800193\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in train:\n",
    "    for col in row:\n",
    "        if np.isnan(col) == False:\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200016\n"
     ]
    }
   ],
   "source": [
    "count_test = 0\n",
    "for row in test:\n",
    "    for col in row:\n",
    "        if np.isnan(col) == False:\n",
    "            count_test += 1\n",
    "print(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_el = []\n",
    "for index, el in np.ndenumerate(train):\n",
    "    if np.isnan(el) == False:\n",
    "        valid_el.append([index, el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 47), 5.0],\n",
       " [(0, 144), 5.0],\n",
       " [(0, 253), 4.0],\n",
       " [(0, 513), 5.0],\n",
       " [(0, 517), 4.0],\n",
       " [(0, 574), 4.0],\n",
       " [(0, 580), 4.0],\n",
       " [(0, 581), 5.0],\n",
       " [(0, 639), 3.0],\n",
       " [(0, 689), 3.0],\n",
       " [(0, 708), 3.0],\n",
       " [(0, 740), 4.0],\n",
       " [(0, 853), 3.0],\n",
       " [(0, 858), 4.0],\n",
       " [(0, 877), 4.0],\n",
       " [(0, 957), 5.0],\n",
       " [(0, 964), 5.0],\n",
       " [(0, 970), 5.0],\n",
       " [(0, 1025), 4.0],\n",
       " [(0, 1104), 5.0],\n",
       " [(0, 1107), 3.0],\n",
       " [(0, 1117), 4.0],\n",
       " [(0, 1178), 5.0],\n",
       " [(0, 1195), 5.0],\n",
       " [(0, 1421), 4.0],\n",
       " [(0, 1574), 4.0],\n",
       " [(0, 1658), 5.0],\n",
       " [(0, 1727), 4.0],\n",
       " [(0, 1781), 5.0],\n",
       " [(0, 2147), 3.0],\n",
       " [(0, 2162), 5.0],\n",
       " [(0, 2205), 4.0],\n",
       " [(0, 2483), 3.0],\n",
       " [(0, 2488), 4.0],\n",
       " [(0, 2557), 4.0],\n",
       " [(0, 2586), 4.0],\n",
       " [(0, 2592), 4.0],\n",
       " [(0, 2599), 5.0],\n",
       " [(0, 2710), 4.0],\n",
       " [(0, 2898), 4.0],\n",
       " [(0, 2969), 4.0],\n",
       " [(0, 3177), 4.0],\n",
       " [(1, 20), 1.0],\n",
       " [(1, 106), 5.0],\n",
       " [(1, 159), 3.0],\n",
       " [(1, 228), 3.0],\n",
       " [(1, 258), 4.0],\n",
       " [(1, 283), 3.0],\n",
       " [(1, 309), 5.0],\n",
       " [(1, 339), 4.0],\n",
       " [(1, 346), 5.0],\n",
       " [(1, 358), 4.0],\n",
       " [(1, 370), 5.0],\n",
       " [(1, 420), 2.0],\n",
       " [(1, 443), 4.0],\n",
       " [(1, 445), 3.0],\n",
       " [(1, 466), 5.0],\n",
       " [(1, 484), 3.0],\n",
       " [(1, 501), 5.0],\n",
       " [(1, 575), 4.0],\n",
       " [(1, 576), 5.0],\n",
       " [(1, 626), 3.0],\n",
       " [(1, 702), 4.0],\n",
       " [(1, 920), 4.0],\n",
       " [(1, 1018), 2.0],\n",
       " [(1, 1024), 4.0],\n",
       " [(1, 1031), 3.0],\n",
       " [(1, 1047), 5.0],\n",
       " [(1, 1099), 4.0],\n",
       " [(1, 1104), 5.0],\n",
       " [(1, 1106), 5.0],\n",
       " [(1, 1108), 4.0],\n",
       " [(1, 1117), 4.0],\n",
       " [(1, 1120), 4.0],\n",
       " [(1, 1123), 2.0],\n",
       " [(1, 1127), 3.0],\n",
       " [(1, 1135), 5.0],\n",
       " [(1, 1152), 3.0],\n",
       " [(1, 1153), 2.0],\n",
       " [(1, 1155), 5.0],\n",
       " [(1, 1167), 5.0],\n",
       " [(1, 1173), 3.0],\n",
       " [(1, 1201), 5.0],\n",
       " [(1, 1259), 5.0],\n",
       " [(1, 1271), 5.0],\n",
       " [(1, 1273), 3.0],\n",
       " [(1, 1306), 3.0],\n",
       " [(1, 1337), 4.0],\n",
       " [(1, 1406), 4.0],\n",
       " [(1, 1414), 4.0],\n",
       " [(1, 1428), 3.0],\n",
       " [(1, 1466), 3.0],\n",
       " [(1, 1478), 5.0],\n",
       " [(1, 1550), 3.0],\n",
       " [(1, 1553), 3.0],\n",
       " [(1, 1618), 5.0],\n",
       " [(1, 1623), 3.0],\n",
       " [(1, 1631), 3.0],\n",
       " [(1, 1656), 4.0],\n",
       " [(1, 1693), 4.0],\n",
       " [(1, 1737), 3.0],\n",
       " [(1, 1765), 5.0],\n",
       " [(1, 1773), 4.0],\n",
       " [(1, 1774), 5.0],\n",
       " [(1, 1775), 4.0],\n",
       " [(1, 1777), 5.0],\n",
       " [(1, 1782), 5.0],\n",
       " [(1, 1822), 5.0],\n",
       " [(1, 1826), 3.0],\n",
       " [(1, 1848), 4.0],\n",
       " [(1, 1886), 5.0],\n",
       " [(1, 2013), 4.0],\n",
       " [(1, 2046), 5.0],\n",
       " [(1, 2086), 3.0],\n",
       " [(1, 2120), 3.0],\n",
       " [(1, 2128), 3.0],\n",
       " [(1, 2203), 4.0],\n",
       " [(1, 2234), 2.0],\n",
       " [(1, 2307), 5.0],\n",
       " [(1, 2512), 3.0],\n",
       " [(1, 2523), 3.0],\n",
       " [(1, 2651), 4.0],\n",
       " [(1, 2674), 3.0],\n",
       " [(1, 2708), 3.0],\n",
       " [(1, 2735), 4.0],\n",
       " [(1, 2816), 4.0],\n",
       " [(1, 2853), 4.0],\n",
       " [(1, 2856), 4.0],\n",
       " [(1, 2889), 4.0],\n",
       " [(1, 2891), 2.0],\n",
       " [(1, 2892), 3.0],\n",
       " [(1, 2931), 5.0],\n",
       " [(1, 3032), 2.0],\n",
       " [(1, 3033), 3.0],\n",
       " [(1, 3107), 4.0],\n",
       " [(1, 3186), 4.0],\n",
       " [(1, 3219), 4.0],\n",
       " [(1, 3235), 5.0],\n",
       " [(1, 3238), 5.0],\n",
       " [(1, 3341), 5.0],\n",
       " [(1, 3436), 3.0],\n",
       " [(1, 3457), 2.0],\n",
       " [(1, 3493), 3.0],\n",
       " [(1, 3566), 3.0],\n",
       " [(1, 3647), 1.0],\n",
       " [(2, 101), 4.0],\n",
       " [(2, 253), 5.0],\n",
       " [(2, 466), 4.0],\n",
       " [(2, 538), 4.0],\n",
       " [(2, 576), 4.0],\n",
       " [(2, 579), 3.0],\n",
       " [(2, 627), 3.0],\n",
       " [(2, 632), 4.0],\n",
       " [(2, 699), 5.0],\n",
       " [(2, 982), 4.0],\n",
       " [(2, 1007), 5.0],\n",
       " [(2, 1106), 4.0],\n",
       " [(2, 1107), 5.0],\n",
       " [(2, 1108), 5.0],\n",
       " [(2, 1120), 4.0],\n",
       " [(2, 1167), 5.0],\n",
       " [(2, 1173), 2.0],\n",
       " [(2, 1174), 5.0],\n",
       " [(2, 1178), 3.0],\n",
       " [(2, 1199), 4.0],\n",
       " [(2, 1212), 5.0],\n",
       " [(2, 1279), 5.0],\n",
       " [(2, 1280), 4.0],\n",
       " [(2, 1295), 4.0],\n",
       " [(2, 1327), 3.0],\n",
       " [(2, 1483), 5.0],\n",
       " [(2, 1504), 2.0],\n",
       " [(2, 1788), 4.0],\n",
       " [(2, 1826), 4.0],\n",
       " [(2, 1900), 4.0],\n",
       " [(2, 1934), 4.0],\n",
       " [(2, 1986), 5.0],\n",
       " [(2, 2277), 4.0],\n",
       " [(2, 2651), 4.0],\n",
       " [(2, 2664), 4.0],\n",
       " [(2, 2785), 3.0],\n",
       " [(2, 2952), 4.0],\n",
       " [(2, 3189), 4.0],\n",
       " [(2, 3318), 5.0],\n",
       " [(2, 3429), 5.0],\n",
       " [(2, 3622), 3.0],\n",
       " [(3, 253), 5.0],\n",
       " [(3, 466), 4.0],\n",
       " [(3, 971), 4.0],\n",
       " [(3, 1025), 4.0],\n",
       " [(3, 1106), 2.0],\n",
       " [(3, 1111), 5.0],\n",
       " [(3, 1120), 3.0],\n",
       " [(3, 1124), 4.0],\n",
       " [(3, 1148), 5.0],\n",
       " [(3, 1288), 5.0],\n",
       " [(3, 1774), 5.0],\n",
       " [(3, 1848), 5.0],\n",
       " [(3, 2173), 4.0],\n",
       " [(3, 2739), 5.0],\n",
       " [(3, 2743), 4.0],\n",
       " [(3, 3186), 4.0],\n",
       " [(3, 3294), 1.0],\n",
       " [(4, 5), 2.0],\n",
       " [(4, 15), 3.0],\n",
       " [(4, 23), 1.0],\n",
       " [(4, 31), 4.0],\n",
       " [(4, 33), 4.0],\n",
       " [(4, 35), 3.0],\n",
       " [(4, 38), 3.0],\n",
       " [(4, 40), 4.0],\n",
       " [(4, 49), 5.0],\n",
       " [(4, 50), 2.0],\n",
       " [(4, 144), 2.0],\n",
       " [(4, 156), 4.0],\n",
       " [(4, 170), 4.0],\n",
       " [(4, 196), 2.0],\n",
       " [(4, 209), 3.0],\n",
       " [(4, 217), 3.0],\n",
       " [(4, 222), 3.0],\n",
       " [(4, 258), 3.0],\n",
       " [(4, 265), 3.0],\n",
       " [(4, 279), 2.0],\n",
       " [(4, 287), 4.0],\n",
       " [(4, 290), 3.0],\n",
       " [(4, 309), 3.0],\n",
       " [(4, 343), 2.0],\n",
       " [(4, 346), 1.0],\n",
       " [(4, 347), 2.0],\n",
       " [(4, 367), 4.0],\n",
       " [(4, 447), 3.0],\n",
       " [(4, 483), 3.0],\n",
       " [(4, 487), 1.0],\n",
       " [(4, 492), 4.0],\n",
       " [(4, 495), 4.0],\n",
       " [(4, 501), 4.0],\n",
       " [(4, 537), 4.0],\n",
       " [(4, 548), 4.0],\n",
       " [(4, 567), 3.0],\n",
       " [(4, 579), 4.0],\n",
       " [(4, 593), 4.0],\n",
       " [(4, 683), 4.0],\n",
       " [(4, 694), 4.0],\n",
       " [(4, 699), 1.0],\n",
       " [(4, 754), 2.0],\n",
       " [(4, 804), 2.0],\n",
       " [(4, 810), 4.0],\n",
       " [(4, 835), 4.0],\n",
       " [(4, 852), 5.0],\n",
       " [(4, 858), 4.0],\n",
       " [(4, 907), 3.0],\n",
       " [(4, 931), 5.0],\n",
       " [(4, 1017), 5.0],\n",
       " [(4, 1021), 2.0],\n",
       " [(4, 1023), 4.0],\n",
       " [(4, 1050), 1.0],\n",
       " [(4, 1083), 4.0],\n",
       " [(4, 1087), 5.0],\n",
       " [(4, 1102), 2.0],\n",
       " [(4, 1103), 5.0],\n",
       " [(4, 1123), 5.0],\n",
       " [(4, 1151), 3.0],\n",
       " [(4, 1158), 5.0],\n",
       " [(4, 1176), 2.0],\n",
       " [(4, 1293), 4.0],\n",
       " [(4, 1325), 3.0],\n",
       " [(4, 1342), 4.0],\n",
       " [(4, 1356), 3.0],\n",
       " [(4, 1371), 3.0],\n",
       " [(4, 1406), 3.0],\n",
       " [(4, 1408), 4.0],\n",
       " [(4, 1413), 4.0],\n",
       " [(4, 1430), 3.0],\n",
       " [(4, 1449), 4.0],\n",
       " [(4, 1478), 4.0],\n",
       " [(4, 1485), 3.0],\n",
       " [(4, 1500), 4.0],\n",
       " [(4, 1513), 3.0],\n",
       " [(4, 1516), 2.0],\n",
       " [(4, 1546), 3.0],\n",
       " [(4, 1547), 3.0],\n",
       " [(4, 1563), 3.0],\n",
       " [(4, 1572), 3.0],\n",
       " [(4, 1574), 1.0],\n",
       " [(4, 1575), 2.0],\n",
       " [(4, 1582), 4.0],\n",
       " [(4, 1586), 4.0],\n",
       " [(4, 1593), 2.0],\n",
       " [(4, 1621), 3.0],\n",
       " [(4, 1704), 3.0],\n",
       " [(4, 1705), 4.0],\n",
       " [(4, 1729), 3.0],\n",
       " [(4, 1741), 4.0],\n",
       " [(4, 1743), 3.0],\n",
       " [(4, 1786), 2.0],\n",
       " [(4, 1848), 2.0],\n",
       " [(4, 1849), 4.0],\n",
       " [(4, 1877), 1.0],\n",
       " [(4, 1889), 2.0],\n",
       " [(4, 2007), 1.0],\n",
       " [(4, 2078), 2.0],\n",
       " [(4, 2090), 3.0],\n",
       " [(4, 2099), 5.0],\n",
       " [(4, 2126), 4.0],\n",
       " [(4, 2130), 4.0],\n",
       " [(4, 2144), 5.0],\n",
       " [(4, 2162), 5.0],\n",
       " [(4, 2166), 3.0],\n",
       " [(4, 2191), 3.0],\n",
       " [(4, 2197), 4.0],\n",
       " [(4, 2202), 5.0],\n",
       " [(4, 2234), 5.0],\n",
       " [(4, 2235), 3.0],\n",
       " [(4, 2244), 2.0],\n",
       " [(4, 2364), 4.0],\n",
       " [(4, 2383), 4.0],\n",
       " [(4, 2400), 5.0],\n",
       " [(4, 2405), 2.0],\n",
       " [(4, 2488), 4.0],\n",
       " [(4, 2495), 4.0],\n",
       " [(4, 2511), 3.0],\n",
       " [(4, 2516), 3.0],\n",
       " [(4, 2518), 4.0],\n",
       " [(4, 2520), 2.0],\n",
       " [(4, 2554), 3.0],\n",
       " [(4, 2557), 3.0],\n",
       " [(4, 2565), 4.0],\n",
       " [(4, 2601), 2.0],\n",
       " [(4, 2651), 4.0],\n",
       " [(4, 2701), 4.0],\n",
       " [(4, 2708), 1.0],\n",
       " [(4, 2744), 2.0],\n",
       " [(4, 2748), 4.0],\n",
       " [(4, 2775), 4.0],\n",
       " [(4, 2785), 5.0],\n",
       " [(4, 2794), 3.0],\n",
       " [(4, 2803), 4.0],\n",
       " [(4, 2837), 2.0],\n",
       " [(4, 2864), 2.0],\n",
       " [(4, 2865), 3.0],\n",
       " [(4, 2867), 5.0],\n",
       " [(4, 2884), 1.0],\n",
       " [(4, 2947), 5.0],\n",
       " [(4, 2959), 2.0],\n",
       " [(4, 3036), 4.0],\n",
       " [(4, 3042), 2.0],\n",
       " [(4, 3043), 4.0],\n",
       " [(4, 3155), 2.0],\n",
       " [(4, 3177), 3.0],\n",
       " [(4, 3178), 3.0],\n",
       " [(4, 3186), 3.0],\n",
       " [(4, 3243), 3.0],\n",
       " [(4, 3266), 3.0],\n",
       " [(4, 3280), 1.0],\n",
       " [(4, 3281), 2.0],\n",
       " [(4, 3341), 2.0],\n",
       " [(4, 3384), 3.0],\n",
       " [(4, 3486), 2.0],\n",
       " [(4, 3502), 1.0],\n",
       " [(4, 3550), 2.0],\n",
       " [(4, 3556), 3.0],\n",
       " [(5, 0), 4.0],\n",
       " [(5, 16), 4.0],\n",
       " [(5, 33), 4.0],\n",
       " [(5, 47), 5.0],\n",
       " [(5, 259), 4.0],\n",
       " [(5, 287), 2.0],\n",
       " [(5, 354), 4.0],\n",
       " [(5, 555), 4.0],\n",
       " [(5, 574), 4.0],\n",
       " [(5, 581), 4.0],\n",
       " [(5, 583), 5.0],\n",
       " [(5, 786), 4.0],\n",
       " [(5, 851), 4.0],\n",
       " [(5, 859), 4.0],\n",
       " [(5, 963), 4.0],\n",
       " [(5, 965), 4.0],\n",
       " [(5, 978), 4.0],\n",
       " [(5, 1016), 5.0],\n",
       " [(5, 1029), 4.0],\n",
       " [(5, 1099), 4.0],\n",
       " [(5, 1120), 3.0],\n",
       " [(5, 1204), 3.0],\n",
       " [(5, 1281), 5.0],\n",
       " [(5, 1336), 4.0],\n",
       " [(5, 1441), 4.0],\n",
       " [(5, 1551), 5.0],\n",
       " [(5, 1634), 3.0],\n",
       " [(5, 1767), 5.0],\n",
       " [(5, 1779), 3.0],\n",
       " [(5, 1826), 4.0],\n",
       " [(5, 1837), 3.0],\n",
       " [(5, 1900), 4.0],\n",
       " [(5, 1901), 3.0],\n",
       " [(5, 1919), 3.0],\n",
       " [(5, 2128), 3.0],\n",
       " [(5, 2203), 4.0],\n",
       " [(5, 2276), 3.0],\n",
       " [(5, 2312), 3.0],\n",
       " [(5, 2597), 4.0],\n",
       " [(5, 2651), 1.0],\n",
       " [(5, 2755), 5.0],\n",
       " [(5, 2857), 4.0],\n",
       " [(5, 2859), 5.0],\n",
       " [(5, 3177), 5.0],\n",
       " [(5, 3275), 3.0],\n",
       " [(5, 3291), 3.0],\n",
       " [(5, 3301), 4.0],\n",
       " [(5, 3303), 5.0],\n",
       " [(5, 3328), 4.0],\n",
       " [(5, 3341), 4.0],\n",
       " [(5, 3364), 5.0],\n",
       " [(5, 3370), 3.0],\n",
       " [(5, 3440), 3.0],\n",
       " [(5, 3443), 3.0],\n",
       " [(5, 3457), 4.0],\n",
       " [(5, 3475), 4.0],\n",
       " [(5, 3510), 5.0],\n",
       " [(6, 5), 4.0],\n",
       " [(6, 106), 5.0],\n",
       " [(6, 339), 5.0],\n",
       " [(6, 370), 5.0],\n",
       " [(6, 443), 5.0],\n",
       " [(6, 460), 5.0],\n",
       " [(6, 466), 4.0],\n",
       " [(6, 627), 4.0],\n",
       " [(6, 699), 5.0],\n",
       " [(6, 805), 4.0],\n",
       " [(6, 1106), 5.0],\n",
       " [(6, 1131), 4.0],\n",
       " [(6, 1445), 4.0],\n",
       " [(6, 1449), 4.0],\n",
       " [(6, 1478), 5.0],\n",
       " [(6, 1575), 4.0],\n",
       " [(6, 1817), 5.0],\n",
       " [(6, 1848), 5.0],\n",
       " [(6, 2160), 5.0],\n",
       " [(6, 2374), 5.0],\n",
       " [(6, 2708), 5.0],\n",
       " [(6, 3032), 5.0],\n",
       " [(6, 3186), 3.0],\n",
       " [(6, 3341), 3.0],\n",
       " [(6, 3510), 4.0],\n",
       " [(7, 0), 4.0],\n",
       " [(7, 3), 3.0],\n",
       " [(7, 13), 4.0],\n",
       " [(7, 15), 4.0],\n",
       " [(7, 16), 4.0],\n",
       " [(7, 24), 5.0],\n",
       " [(7, 35), 4.0],\n",
       " [(7, 38), 3.0],\n",
       " [(7, 41), 3.0],\n",
       " [(7, 56), 5.0],\n",
       " [(7, 71), 4.0],\n",
       " [(7, 102), 4.0],\n",
       " [(7, 106), 5.0],\n",
       " [(7, 144), 4.0],\n",
       " [(7, 145), 4.0],\n",
       " [(7, 155), 3.0],\n",
       " [(7, 157), 5.0],\n",
       " [(7, 223), 4.0],\n",
       " [(7, 258), 4.0],\n",
       " [(7, 259), 4.0],\n",
       " [(7, 262), 4.0],\n",
       " [(7, 287), 5.0],\n",
       " [(7, 335), 3.0],\n",
       " [(7, 367), 4.0],\n",
       " [(7, 383), 2.0],\n",
       " [(7, 440), 3.0],\n",
       " [(7, 451), 5.0],\n",
       " [(7, 462), 3.0],\n",
       " [(7, 492), 3.0],\n",
       " [(7, 494), 3.0],\n",
       " [(7, 496), 3.0],\n",
       " [(7, 510), 5.0],\n",
       " [(7, 513), 4.0],\n",
       " [(7, 541), 4.0],\n",
       " [(7, 593), 5.0],\n",
       " [(7, 629), 5.0],\n",
       " [(7, 699), 3.0],\n",
       " [(7, 847), 5.0],\n",
       " [(7, 962), 4.0],\n",
       " [(7, 991), 3.0],\n",
       " [(7, 1044), 4.0],\n",
       " [(7, 1120), 4.0],\n",
       " [(7, 1123), 5.0],\n",
       " [(7, 1173), 5.0],\n",
       " [(7, 1182), 5.0],\n",
       " [(7, 1185), 3.0],\n",
       " [(7, 1259), 4.0],\n",
       " [(7, 1294), 5.0],\n",
       " [(7, 1356), 4.0],\n",
       " [(7, 1364), 3.0],\n",
       " [(7, 1445), 4.0],\n",
       " [(7, 1449), 4.0],\n",
       " [(7, 1488), 3.0],\n",
       " [(7, 1502), 5.0],\n",
       " [(7, 1516), 5.0],\n",
       " [(7, 1523), 3.0],\n",
       " [(7, 1536), 5.0],\n",
       " [(7, 1541), 5.0],\n",
       " [(7, 1545), 4.0],\n",
       " [(7, 1555), 3.0],\n",
       " [(7, 1560), 4.0],\n",
       " [(7, 1563), 5.0],\n",
       " [(7, 1566), 3.0],\n",
       " [(7, 1574), 5.0],\n",
       " [(7, 1587), 4.0],\n",
       " [(7, 1631), 3.0],\n",
       " [(7, 1658), 4.0],\n",
       " [(7, 1736), 5.0],\n",
       " [(7, 1826), 3.0],\n",
       " [(7, 1848), 5.0],\n",
       " [(7, 2078), 3.0],\n",
       " [(7, 2086), 3.0],\n",
       " [(7, 2099), 5.0],\n",
       " [(7, 2105), 3.0],\n",
       " [(7, 2122), 3.0],\n",
       " [(7, 2127), 2.0],\n",
       " [(7, 2136), 5.0],\n",
       " [(7, 2203), 5.0],\n",
       " [(7, 2234), 5.0],\n",
       " [(7, 2249), 4.0],\n",
       " [(7, 2296), 2.0],\n",
       " [(7, 2374), 5.0],\n",
       " [(7, 2401), 2.0],\n",
       " [(7, 2482), 4.0],\n",
       " [(7, 2488), 5.0],\n",
       " [(7, 2494), 5.0],\n",
       " [(7, 2497), 3.0],\n",
       " [(7, 2507), 3.0],\n",
       " [(7, 2651), 5.0],\n",
       " [(7, 2701), 3.0],\n",
       " [(7, 2889), 4.0],\n",
       " [(7, 2891), 5.0],\n",
       " [(7, 2931), 5.0],\n",
       " [(7, 2932), 3.0],\n",
       " [(7, 2939), 3.0],\n",
       " [(7, 2956), 2.0],\n",
       " [(7, 2969), 4.0],\n",
       " [(7, 2993), 3.0],\n",
       " [(7, 3022), 4.0],\n",
       " [(7, 3026), 3.0],\n",
       " [(7, 3028), 3.0],\n",
       " [(7, 3032), 5.0],\n",
       " [(7, 3033), 3.0],\n",
       " [(7, 3035), 4.0],\n",
       " [(7, 3036), 3.0],\n",
       " [(7, 3155), 3.0],\n",
       " [(7, 3186), 3.0],\n",
       " [(7, 3193), 3.0],\n",
       " [(7, 3248), 4.0],\n",
       " [(7, 3267), 3.0],\n",
       " [(7, 3295), 4.0],\n",
       " [(8, 0), 5.0],\n",
       " [(8, 15), 4.0],\n",
       " [(8, 24), 4.0],\n",
       " [(8, 46), 5.0],\n",
       " [(8, 49), 4.0],\n",
       " [(8, 156), 4.0],\n",
       " [(8, 216), 4.0],\n",
       " [(8, 291), 4.0],\n",
       " [(8, 309), 5.0],\n",
       " [(8, 339), 4.0],\n",
       " [(8, 357), 3.0],\n",
       " [(8, 398), 3.0],\n",
       " [(8, 414), 3.0],\n",
       " [(8, 443), 5.0],\n",
       " [(8, 466), 4.0],\n",
       " [(8, 510), 4.0],\n",
       " [(8, 513), 5.0],\n",
       " [(8, 515), 5.0],\n",
       " [(8, 576), 5.0],\n",
       " [(8, 579), 5.0],\n",
       " [(8, 593), 4.0],\n",
       " [(8, 689), 4.0],\n",
       " [(8, 708), 4.0],\n",
       " [(8, 735), 5.0],\n",
       " [(8, 759), 3.0],\n",
       " [(8, 786), 3.0],\n",
       " [(8, 851), 4.0],\n",
       " [(8, 931), 4.0],\n",
       " [(8, 992), 4.0],\n",
       " [(8, 1017), 4.0],\n",
       " [(8, 1066), 4.0],\n",
       " [(8, 1120), 4.0],\n",
       " [(8, 1131), 4.0],\n",
       " [(8, 1133), 4.0],\n",
       " [(8, 1142), 3.0],\n",
       " [(8, 1173), 4.0],\n",
       " [(8, 1215), 4.0],\n",
       " [(8, 1216), 3.0],\n",
       " [(8, 1245), 3.0],\n",
       " [(8, 1260), 4.0],\n",
       " [(8, 1294), 3.0],\n",
       " [(8, 1340), 3.0],\n",
       " [(8, 1356), 4.0],\n",
       " [(8, 1428), 2.0],\n",
       " [(8, 1485), 4.0],\n",
       " [(8, 1516), 4.0],\n",
       " [(8, 1532), 3.0],\n",
       " [(8, 1545), 4.0],\n",
       " [(8, 1563), 4.0],\n",
       " [(8, 1574), 5.0],\n",
       " [(8, 1613), 4.0],\n",
       " [(8, 1618), 3.0],\n",
       " [(8, 1732), 3.0],\n",
       " [(8, 1741), 4.0],\n",
       " [(8, 1781), 5.0],\n",
       " [(8, 1848), 5.0],\n",
       " [(8, 2102), 4.0],\n",
       " [(8, 2110), 4.0],\n",
       " [(8, 2162), 4.0],\n",
       " [(8, 2374), 5.0],\n",
       " [(8, 2400), 2.0],\n",
       " [(8, 2651), 4.0],\n",
       " [(8, 2683), 5.0],\n",
       " [(8, 2748), 4.0],\n",
       " [(8, 2794), 3.0],\n",
       " [(8, 2898), 4.0],\n",
       " [(8, 2931), 4.0],\n",
       " [(8, 2944), 3.0],\n",
       " [(8, 2961), 3.0],\n",
       " [(8, 3029), 4.0],\n",
       " [(8, 3046), 3.0],\n",
       " [(8, 3072), 4.0],\n",
       " [(8, 3075), 2.0],\n",
       " [(8, 3220), 2.0],\n",
       " [(8, 3251), 2.0],\n",
       " [(8, 3277), 3.0],\n",
       " [(8, 3280), 3.0],\n",
       " [(8, 3383), 4.0],\n",
       " [(8, 3475), 3.0],\n",
       " [(8, 3508), 4.0],\n",
       " [(8, 3512), 2.0],\n",
       " [(8, 3550), 4.0],\n",
       " [(8, 3582), 2.0],\n",
       " [(8, 3669), 3.0],\n",
       " [(8, 3701), 3.0],\n",
       " [(9, 1), 5.0],\n",
       " [(9, 6), 4.0],\n",
       " [(9, 23), 3.0],\n",
       " [(9, 31), 5.0],\n",
       " [(9, 47), 4.0],\n",
       " [(9, 60), 5.0],\n",
       " [(9, 101), 3.0],\n",
       " [(9, 106), 4.0],\n",
       " [(9, 111), 3.0],\n",
       " [(9, 144), 5.0],\n",
       " [(9, 147), 3.0],\n",
       " [(9, 174), 2.0],\n",
       " [(9, 197), 4.0],\n",
       " [(9, 202), 4.0],\n",
       " [(9, 216), 2.0],\n",
       " [(9, 253), 5.0],\n",
       " [(9, 268), 4.0],\n",
       " [(9, 275), 5.0],\n",
       " [(9, 283), 4.0],\n",
       " [(9, 307), 5.0],\n",
       " [(9, 309), 4.0],\n",
       " [(9, 319), 5.0],\n",
       " [(9, 323), 3.0],\n",
       " [(9, 329), 5.0],\n",
       " [(9, 334), 4.0],\n",
       " [(9, 341), 4.0],\n",
       " [(9, 346), 5.0],\n",
       " [(9, 354), 4.0],\n",
       " [(9, 358), 4.0],\n",
       " [(9, 360), 3.0],\n",
       " [(9, 421), 4.0],\n",
       " [(9, 466), 4.0],\n",
       " [(9, 513), 4.0],\n",
       " [(9, 525), 5.0],\n",
       " [(9, 527), 5.0],\n",
       " [(9, 529), 4.0],\n",
       " [(9, 537), 3.0],\n",
       " [(9, 573), 5.0],\n",
       " [(9, 574), 4.0],\n",
       " [(9, 576), 5.0],\n",
       " [(9, 578), 4.0],\n",
       " [(9, 581), 5.0],\n",
       " [(9, 582), 4.0],\n",
       " [(9, 583), 4.0],\n",
       " [(9, 632), 4.0],\n",
       " [(9, 689), 5.0],\n",
       " [(9, 708), 5.0],\n",
       " [(9, 713), 4.0],\n",
       " [(9, 727), 4.0],\n",
       " [(9, 737), 5.0],\n",
       " [(9, 741), 3.0],\n",
       " [(9, 756), 5.0],\n",
       " [(9, 778), 5.0],\n",
       " [(9, 837), 4.0],\n",
       " [(9, 838), 4.0],\n",
       " [(9, 841), 5.0],\n",
       " [(9, 843), 4.0],\n",
       " [(9, 851), 3.0],\n",
       " [(9, 854), 5.0],\n",
       " [(9, 855), 5.0],\n",
       " [(9, 857), 5.0],\n",
       " [(9, 858), 5.0],\n",
       " [(9, 862), 3.0],\n",
       " [(9, 863), 3.0],\n",
       " [(9, 865), 4.0],\n",
       " [(9, 871), 2.0],\n",
       " [(9, 877), 4.0],\n",
       " [(9, 882), 4.0],\n",
       " [(9, 892), 5.0],\n",
       " [(9, 893), 5.0],\n",
       " [(9, 902), 5.0],\n",
       " [(9, 908), 3.0],\n",
       " [(9, 950), 3.0],\n",
       " [(9, 951), 5.0],\n",
       " [(9, 954), 4.0],\n",
       " [(9, 957), 5.0],\n",
       " [(9, 960), 4.0],\n",
       " [(9, 965), 3.0],\n",
       " [(9, 967), 4.0],\n",
       " [(9, 970), 5.0],\n",
       " [(9, 977), 5.0],\n",
       " [(9, 991), 5.0],\n",
       " [(9, 1003), 5.0],\n",
       " [(9, 1007), 5.0],\n",
       " [(9, 1008), 5.0],\n",
       " [(9, 1012), 4.0],\n",
       " [(9, 1016), 5.0],\n",
       " [(9, 1019), 3.0],\n",
       " [(9, 1025), 5.0],\n",
       " [(9, 1029), 4.0],\n",
       " [(9, 1032), 4.0],\n",
       " [(9, 1047), 5.0],\n",
       " [(9, 1048), 4.0],\n",
       " [(9, 1050), 4.0],\n",
       " [(9, 1052), 4.0],\n",
       " [(9, 1058), 4.0],\n",
       " [(9, 1059), 4.0],\n",
       " [(9, 1066), 5.0],\n",
       " [(9, 1108), 5.0],\n",
       " [(9, 1110), 5.0],\n",
       " [(9, 1114), 4.0],\n",
       " [(9, 1120), 4.0],\n",
       " [(9, 1124), 4.0],\n",
       " [(9, 1125), 4.0],\n",
       " [(9, 1131), 3.0],\n",
       " [(9, 1133), 5.0],\n",
       " [(9, 1135), 4.0],\n",
       " [(9, 1139), 4.0],\n",
       " [(9, 1142), 4.0],\n",
       " [(9, 1143), 4.0],\n",
       " [(9, 1148), 5.0],\n",
       " [(9, 1151), 5.0],\n",
       " [(9, 1155), 3.0],\n",
       " [(9, 1158), 3.0],\n",
       " [(9, 1161), 5.0],\n",
       " [(9, 1165), 5.0],\n",
       " [(9, 1167), 3.0],\n",
       " [(9, 1173), 5.0],\n",
       " [(9, 1179), 5.0],\n",
       " [(9, 1184), 3.0],\n",
       " [(9, 1186), 5.0],\n",
       " [(9, 1191), 3.0],\n",
       " [(9, 1199), 5.0],\n",
       " [(9, 1201), 4.0],\n",
       " [(9, 1202), 4.0],\n",
       " [(9, 1210), 5.0],\n",
       " [(9, 1215), 5.0],\n",
       " [(9, 1241), 5.0],\n",
       " [(9, 1247), 3.0],\n",
       " [(9, 1258), 5.0],\n",
       " [(9, 1272), 4.0],\n",
       " [(9, 1273), 4.0],\n",
       " [(9, 1275), 4.0],\n",
       " [(9, 1276), 4.0],\n",
       " [(9, 1277), 4.0],\n",
       " [(9, 1278), 3.0],\n",
       " [(9, 1281), 5.0],\n",
       " [(9, 1288), 3.0],\n",
       " [(9, 1306), 4.0],\n",
       " [(9, 1307), 5.0],\n",
       " [(9, 1309), 4.0],\n",
       " [(9, 1336), 5.0],\n",
       " [(9, 1394), 3.0],\n",
       " [(9, 1398), 3.0],\n",
       " [(9, 1420), 4.0],\n",
       " [(9, 1439), 3.0],\n",
       " [(9, 1445), 5.0],\n",
       " [(9, 1449), 5.0],\n",
       " [(9, 1452), 4.0],\n",
       " [(9, 1453), 5.0],\n",
       " [(9, 1455), 4.0],\n",
       " [(9, 1485), 3.0],\n",
       " [(9, 1516), 5.0],\n",
       " [(9, 1517), 5.0],\n",
       " [(9, 1539), 4.0],\n",
       " [(9, 1545), 5.0],\n",
       " [(9, 1553), 4.0],\n",
       " [(9, 1563), 5.0],\n",
       " [(9, 1574), 3.0],\n",
       " [(9, 1601), 4.0],\n",
       " [(9, 1704), 2.0],\n",
       " [(9, 1738), 3.0],\n",
       " [(9, 1741), 4.0],\n",
       " [(9, 1747), 3.0],\n",
       " [(9, 1767), 5.0],\n",
       " [(9, 1768), 4.0],\n",
       " [(9, 1774), 3.0],\n",
       " [(9, 1779), 5.0],\n",
       " [(9, 1781), 5.0],\n",
       " [(9, 1820), 5.0],\n",
       " [(9, 1821), 4.0],\n",
       " [(9, 1822), 4.0],\n",
       " [(9, 1823), 4.0],\n",
       " [(9, 1825), 4.0],\n",
       " [(9, 1826), 3.0],\n",
       " [(9, 1829), 4.0],\n",
       " [(9, 1831), 4.0],\n",
       " [(9, 1832), 5.0],\n",
       " [(9, 1852), 3.0],\n",
       " [(9, 1859), 4.0],\n",
       " [(9, 1862), 5.0],\n",
       " [(9, 1864), 3.0],\n",
       " [(9, 1865), 4.0],\n",
       " [(9, 1866), 4.0],\n",
       " [(9, 1886), 3.0],\n",
       " [(9, 1891), 4.0],\n",
       " [(9, 1896), 3.0],\n",
       " [(9, 1899), 4.0],\n",
       " [(9, 1900), 5.0],\n",
       " [(9, 1910), 3.0],\n",
       " [(9, 1912), 4.0],\n",
       " [(9, 1913), 4.0],\n",
       " [(9, 1915), 5.0],\n",
       " [(9, 1919), 5.0],\n",
       " [(9, 1927), 5.0],\n",
       " [(9, 1928), 4.0],\n",
       " [(9, 1930), 4.0],\n",
       " [(9, 1934), 5.0],\n",
       " [(9, 1943), 3.0],\n",
       " [(9, 1944), 5.0],\n",
       " [(9, 1952), 4.0],\n",
       " [(9, 1954), 4.0],\n",
       " [(9, 1955), 4.0],\n",
       " [(9, 1956), 4.0],\n",
       " [(9, 1957), 3.0],\n",
       " [(9, 1959), 5.0],\n",
       " [(9, 1980), 5.0],\n",
       " [(9, 1993), 5.0],\n",
       " [(9, 2099), 4.0],\n",
       " [(9, 2102), 4.0],\n",
       " [(9, 2108), 5.0],\n",
       " [(9, 2110), 5.0],\n",
       " [(9, 2120), 5.0],\n",
       " [(9, 2124), 4.0],\n",
       " [(9, 2128), 4.0],\n",
       " [(9, 2131), 5.0],\n",
       " [(9, 2143), 5.0],\n",
       " [(9, 2178), 4.0],\n",
       " [(9, 2182), 4.0],\n",
       " [(9, 2185), 3.0],\n",
       " [(9, 2200), 4.0],\n",
       " [(9, 2203), 5.0],\n",
       " [(9, 2205), 5.0],\n",
       " [(9, 2206), 4.0],\n",
       " [(9, 2214), 5.0],\n",
       " [(9, 2230), 5.0],\n",
       " [(9, 2231), 5.0],\n",
       " [(9, 2243), 5.0],\n",
       " [(9, 2260), 4.0],\n",
       " [(9, 2277), 5.0],\n",
       " [(9, 2302), 4.0],\n",
       " [(9, 2303), 4.0],\n",
       " [(9, 2304), 4.0],\n",
       " [(9, 2307), 5.0],\n",
       " [(9, 2334), 4.0],\n",
       " [(9, 2335), 3.0],\n",
       " [(9, 2400), 5.0],\n",
       " [(9, 2415), 4.0],\n",
       " [(9, 2420), 5.0],\n",
       " [(9, 2426), 3.0],\n",
       " [(9, 2455), 4.0],\n",
       " [(9, 2460), 4.0],\n",
       " [(9, 2489), 5.0],\n",
       " [(9, 2511), 4.0],\n",
       " [(9, 2512), 4.0],\n",
       " [(9, 2541), 5.0],\n",
       " [(9, 2557), 5.0],\n",
       " [(9, 2565), 4.0],\n",
       " [(9, 2586), 4.0],\n",
       " [(9, 2590), 3.0],\n",
       " [(9, 2592), 5.0],\n",
       " [(9, 2599), 5.0],\n",
       " [(9, 2621), 4.0],\n",
       " [(9, 2651), 3.0],\n",
       " [(9, 2665), 4.0],\n",
       " [(9, 2667), 5.0],\n",
       " [(9, 2738), 3.0],\n",
       " [(9, 2740), 4.0],\n",
       " [(9, 2748), 3.0],\n",
       " [(9, 2756), 4.0],\n",
       " [(9, 2757), 4.0],\n",
       " [(9, 2820), 4.0],\n",
       " [(9, 2821), 3.0],\n",
       " [(9, 2823), 5.0],\n",
       " [(9, 2851), 2.0],\n",
       " [(9, 2857), 4.0],\n",
       " [(9, 2870), 4.0],\n",
       " [(9, 2871), 5.0],\n",
       " [(9, 2879), 4.0],\n",
       " [(9, 2883), 3.0],\n",
       " [(9, 2884), 3.0],\n",
       " [(9, 2892), 5.0],\n",
       " [(9, 2898), 4.0],\n",
       " [(9, 2937), 2.0],\n",
       " [(9, 2939), 5.0],\n",
       " [(9, 2957), 4.0],\n",
       " [(9, 2958), 5.0],\n",
       " [(9, 2972), 4.0],\n",
       " [(9, 2975), 4.0],\n",
       " [(9, 3023), 4.0],\n",
       " [(9, 3028), 3.0],\n",
       " [(9, 3035), 5.0],\n",
       " [(9, 3040), 3.0],\n",
       " [(9, 3070), 4.0],\n",
       " [(9, 3083), 3.0],\n",
       " [(9, 3120), 5.0],\n",
       " [(9, 3129), 5.0],\n",
       " [(9, 3134), 5.0],\n",
       " [(9, 3155), 4.0],\n",
       " [(9, 3157), 3.0],\n",
       " [(9, 3177), 4.0],\n",
       " [(9, 3206), 3.0],\n",
       " [(9, 3207), 2.0],\n",
       " [(9, 3215), 5.0],\n",
       " [(9, 3219), 5.0],\n",
       " [(9, 3233), 5.0],\n",
       " [(9, 3238), 5.0],\n",
       " [(9, 3248), 4.0],\n",
       " [(9, 3256), 4.0],\n",
       " [(9, 3267), 5.0],\n",
       " [(9, 3268), 5.0],\n",
       " [(9, 3292), 2.0],\n",
       " [(9, 3351), 5.0],\n",
       " [(9, 3353), 4.0],\n",
       " [(9, 3368), 3.0],\n",
       " [(9, 3389), 3.0],\n",
       " [(9, 3426), 4.0],\n",
       " [(9, 3429), 4.0],\n",
       " [(9, 3433), 5.0],\n",
       " [(9, 3457), 5.0],\n",
       " [(9, 3459), 3.0],\n",
       " [(9, 3460), 3.0],\n",
       " [(9, 3461), 2.0],\n",
       " [(9, 3462), 2.0],\n",
       " [(9, 3481), 4.0],\n",
       " [(9, 3508), 5.0],\n",
       " [(9, 3569), 4.0],\n",
       " [(9, 3622), 3.0],\n",
       " [(9, 3623), 3.0],\n",
       " [(9, 3681), 4.0],\n",
       " [(9, 3701), 4.0],\n",
       " [(10, 35), 3.0],\n",
       " [(10, 46), 3.0],\n",
       " [(10, 49), 5.0],\n",
       " [(10, 86), 4.0],\n",
       " [(10, 101), 5.0],\n",
       " [(10, 224), 3.0],\n",
       " [(10, 239), 4.0],\n",
       " [(10, 265), 2.0],\n",
       " [(10, 323), 4.0],\n",
       " [(10, 332), 3.0],\n",
       " [(10, 335), 4.0],\n",
       " [(10, 346), 5.0],\n",
       " [(10, 421), 1.0],\n",
       " [(10, 426), 2.0],\n",
       " [(10, 440), 2.0],\n",
       " [(10, 466), 4.0],\n",
       " [(10, 467), 5.0],\n",
       " [(10, 501), 3.0],\n",
       " [(10, 517), 3.0],\n",
       " [(10, 529), 5.0],\n",
       " [(10, 537), 3.0],\n",
       " [(10, 573), 3.0],\n",
       " [(10, 576), 3.0],\n",
       " [(10, 579), 5.0],\n",
       " [(10, 593), 5.0],\n",
       " [(10, 641), 4.0],\n",
       " [(10, 678), 1.0],\n",
       " [(10, 726), 5.0],\n",
       " [(10, 735), 4.0],\n",
       " [(10, 741), 2.0],\n",
       " [(10, 745), 1.0],\n",
       " [(10, 991), 4.0],\n",
       " [(10, 1059), 4.0],\n",
       " [(10, 1099), 4.0],\n",
       " [(10, 1107), 5.0],\n",
       " [(10, 1108), 4.0],\n",
       " [(10, 1123), 4.0],\n",
       " [(10, 1152), 4.0],\n",
       " [(10, 1167), 3.0],\n",
       " [(10, 1186), 3.0],\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD():\n",
    "    def __init__(self, threadID, train_set, test_set, K_features=10, lr=0.005, reg=0.05, epoch=75):\n",
    "        self.threadID =  threadID\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.K_features = K_features\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.epoch = epoch\n",
    "    \n",
    "    # initialize params\n",
    "    def initialize_latent_vectors(self):\n",
    "        # To be reproducible\n",
    "        np.random.seed(11)\n",
    "        self.U = np.random.rand(self.train_set.shape[0], self.K_features)\n",
    "        np.random.seed(44)\n",
    "        self.M = np.random.rand(self.K_features, self.train_set.shape[1])\n",
    "    \n",
    "    # 1) loss function\n",
    "    def MAE(self, dataset):\n",
    "        mask = np.isnan(dataset)\n",
    "        masked_array = ma.array(dataset, mask=mask)\n",
    "        error = masked_array - np.matmul(self.U, self.M)\n",
    "        MAE = np.mean(np.absolute(error))\n",
    "        return MAE\n",
    "\n",
    "    # 2) loss function\n",
    "    def RMSE(self, dataset):\n",
    "        mask = np.isnan(dataset)\n",
    "        masked_array = ma.array(dataset, mask=mask)\n",
    "        error = masked_array - np.matmul(self.U, self.M)\n",
    "        RMSE = np.mean(error**2) ** 0.5\n",
    "        return RMSE\n",
    "    \n",
    "    def update_params(self, i, j, error):\n",
    "        self.U[i,:] += self.lr * (2 * error * self.M[:,j] - self.reg * self.U[i,:])\n",
    "        self.M[:,j] += self.lr * (2 * error * self.U[i,:] - self.reg * self.M[:,j])\n",
    "    \n",
    "    def save_params(self):\n",
    "        joblib.dump(self.U, 'U_vec'+str(self.threadID))\n",
    "        joblib.dump(self.M, 'M_vec'+str(self.threadID))\n",
    "    \n",
    "    def load_params(self):\n",
    "        self.U = joblib.load('U_vec'+str(self.threadID))\n",
    "        self.M = joblib.load('M_vec'+str(self.threadID))\n",
    "\n",
    "    def testing(self):\n",
    "        MAE = self.MAE(self.test_set)\n",
    "        RMSE = self.RMSE(self.test_set)\n",
    "        print('Thread-->',self.threadID,' Test-->', 'RMSE: ', RMSE, 'MAE: ', MAE)\n",
    "        \n",
    "    \n",
    "    # training\n",
    "    def training(self, retrain=False):\n",
    "\n",
    "        if retrain:\n",
    "            self.load_params()\n",
    "            print('Thread-->',self.threadID,' Params loaded')\n",
    "        else:\n",
    "        # initialize params\n",
    "            self.initialize_latent_vectors()\n",
    "\n",
    "        # start training\n",
    "        '''\n",
    "        1) Iterate over each known element \n",
    "        2) update the ith row of U and the jth column of M.\n",
    "        '''\n",
    "        valid_el = []\n",
    "        for index, el in np.ndenumerate(self.train_set):\n",
    "                if isnan(el) == False:\n",
    "                    valid_el.append([index, el])\n",
    "        # start training\n",
    "        for epoch in range(self.epoch):\n",
    "            # valid_el->foramt: [[(i,j),rating],...]\n",
    "            for index, rating_idx in enumerate(valid_el):\n",
    "                i = rating_idx[0][0]\n",
    "                j = rating_idx[0][1]\n",
    "                rating = rating_idx[1]\n",
    "                pred = np.dot(self.U[i,:], self.M[:, j]) # row vec * col vec\n",
    "                error = rating - pred # get error\n",
    "                # update each param item\n",
    "                # print(i,'',j, '', rating)\n",
    "                self.update_params(i, j, error)\n",
    "                if index % 10 == 0:\n",
    "                    MAE = self.MAE(self.train_set)\n",
    "                    RMSE = self.RMSE(self.train_set)\n",
    "                    print('Thread-->',self.threadID,' Train-->', ' Epoch: ', epoch, 'RMSE: ', RMSE, 'MAE: ', MAE)\n",
    "                if index != 0 and index % 500 == 0:\n",
    "                    self.save_params()\n",
    "                    print('Thread-->',self.threadID,' Params saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21, 1.0], [95, 2.0], [110, 5.0], [163, 4.0], [165, 3.0], [235, 3.0], [265, 4.0], [292, 3.0], [318, 5.0], [349, 4.0], [356, 5.0], [368, 4.0], [380, 5.0], [434, 2.0], [442, 3.0], [457, 4.0], [459, 3.0], [480, 5.0], [498, 3.0], [515, 5.0], [589, 4.0], [590, 5.0], [593, 5.0], [647, 3.0], [648, 4.0], [736, 4.0], [780, 3.0], [902, 2.0], [920, 5.0], [982, 4.0], [1084, 3.0], [1090, 2.0], [1096, 4.0], [1103, 3.0], [1124, 5.0], [1188, 4.0], [1193, 5.0], [1196, 5.0], [1198, 4.0], [1207, 4.0], [1210, 4.0], [1213, 2.0], [1217, 3.0], [1225, 5.0], [1244, 3.0], [1245, 2.0], [1246, 5.0], [1247, 5.0], [1253, 3.0], [1259, 5.0], [1265, 3.0], [1293, 5.0], [1357, 5.0], [1370, 5.0], [1372, 3.0], [1385, 3.0], [1408, 3.0], [1442, 4.0], [1527, 4.0], [1537, 4.0], [1544, 4.0], [1552, 3.0], [1597, 3.0], [1610, 5.0], [1687, 3.0], [1690, 3.0], [1784, 5.0], [1792, 3.0], [1801, 3.0], [1834, 4.0], [1873, 4.0], [1917, 3.0], [1945, 5.0], [1953, 4.0], [1954, 5.0], [1955, 4.0], [1957, 5.0], [1962, 5.0], [1968, 2.0], [2002, 5.0], [2006, 3.0], [2028, 4.0], [2067, 5.0], [2126, 3.0], [2194, 4.0], [2236, 5.0], [2268, 5.0], [2278, 3.0], [2312, 3.0], [2321, 3.0], [2353, 4.0], [2359, 3.0], [2396, 4.0], [2427, 2.0], [2490, 3.0], [2501, 5.0], [2571, 4.0], [2628, 3.0], [2717, 3.0], [2728, 3.0], [2852, 3.0], [2858, 4.0], [2881, 3.0], [2916, 3.0], [2943, 4.0], [3030, 4.0], [3035, 4.0], [3068, 4.0], [3071, 4.0], [3095, 4.0], [3105, 4.0], [3107, 2.0], [3108, 3.0], [3147, 5.0], [3255, 4.0], [3256, 2.0], [3257, 3.0], [3334, 4.0], [3418, 4.0], [3451, 4.0], [3468, 5.0], [3471, 5.0], [3578, 5.0], [3654, 3.0], [3678, 3.0], [3699, 2.0], [3735, 3.0], [3809, 3.0], [3893, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CrossValidation('ratings.dat')\n",
    "dataset = cv.split(fold=5) # split and get 5 dataset including train&test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(self):\n",
    "        ratings = pd.read_csv(\n",
    "            self.file_path,\n",
    "            sep='::',\n",
    "            engine='python',\n",
    "            header=None,\n",
    "            names=['UserID','MovieID','Rating','Timestamp'])\n",
    "\n",
    "        ratings = ratings.pivot(\n",
    "            index = 'UserID', \n",
    "            columns ='MovieID', \n",
    "            values = 'Rating')\n",
    "        return ratings\n",
    "    \n",
    "    def split(self, fold=5, all=False, save=False):\n",
    "\n",
    "        # alpha = round((fold - 1) / fold, 1)\n",
    "\n",
    "        # process raw data\n",
    "        ratings = self.process_dataset()\n",
    "\n",
    "        # not folding but regarding whole dataset as train set\n",
    "        if all:\n",
    "            return ratings.to_numpy()\n",
    "        \n",
    "        dict_ratings_valid = dict()\n",
    "        for i, row in ratings.iterrows():\n",
    "            u_rating = row[np.isnan(row) == False]\n",
    "            u_rating_j = list(u_rating.index)\n",
    "            u_rating = list(u_rating)\n",
    "            value = list(zip(u_rating_j,u_rating))\n",
    "            random.seed(88)\n",
    "            random.shuffle(value)\n",
    "            dict_ratings_valid[i] = value\n",
    "        \n",
    "        results = []\n",
    "        for num in range(fold):\n",
    "            dict_ratings_valid_train = dict()\n",
    "            dict_ratings_valid_test = dict()\n",
    "            fold_idx = [i for i in range(fold)]\n",
    "            fold_idx.remove(num)\n",
    "            for user_id in dict_ratings_valid.keys():\n",
    "                tmp = [dict_ratings_valid[user_id][i::fold] for i in range(fold)]\n",
    "                dict_ratings_valid_test[user_id] = tmp[num]\n",
    "                tr_tmp = []\n",
    "                for idx in fold_idx:\n",
    "                    tr_tmp.extend(tmp[idx]) \n",
    "                dict_ratings_valid_train[user_id] = tr_tmp\n",
    "            results.append([dict_ratings_valid_train, dict_ratings_valid_test])\n",
    "        \n",
    "        # results    [x]    [y]    [z]\n",
    "        # format  |k-fold|tr/tst|user_id|\n",
    "        return results, ratings.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isnan\n",
    "import joblib\n",
    "import numpy.ma as ma\n",
    "import threading\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-threads\n",
    "class Threads(threading.Thread):\n",
    "    def __init__(self, threadID, train_set, test_set, lr=0.005, k_factors=10):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.lr = lr\n",
    "        self.k_factors = k_factors\n",
    "    \n",
    "    def run(self):\n",
    "        model = SVD(\n",
    "            self.threadID, \n",
    "            self.train_set, \n",
    "            self.test_set, \n",
    "            lr=self.lr,\n",
    "            K_features=self.k_factors)\n",
    "        model.training(retrain=False)\n",
    "\n",
    "# cv for User/Movie matrix only\n",
    "class CrossValidation():\n",
    "    def __init__(self, file_path, shuffle=True, normolize=False):\n",
    "        self.file_path = file_path\n",
    "        self.normolize = normolize\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def load_dataset(self, train_set_path, test_set_path):\n",
    "        return joblib.load(train_set_path), joblib.load(test_set_path)\n",
    "\n",
    "    def process_dataset(self):\n",
    "        ratings = pd.read_csv(\n",
    "            self.file_path,\n",
    "            sep='::',\n",
    "            engine='python',\n",
    "            header=None,\n",
    "            names=['UserID','MovieID','Rating','Timestamp'])\n",
    "\n",
    "        ratings = ratings.pivot(\n",
    "            index = 'UserID', \n",
    "            columns ='MovieID', \n",
    "            values = 'Rating')\n",
    "        return ratings\n",
    "    \n",
    "    def split(self, fold=5, all=False, save=False):\n",
    "\n",
    "        # process raw data\n",
    "        ratings = self.process_dataset()\n",
    "\n",
    "        # not folding but regarding whole dataset as train set\n",
    "        if all:\n",
    "            return ratings.to_numpy()\n",
    "        \n",
    "        dict_ratings_valid = dict()\n",
    "        for i, row in ratings.iterrows():\n",
    "            u_rating = row[np.isnan(row) == False]\n",
    "            u_rating_j = list(u_rating.index)\n",
    "            random.seed(88)\n",
    "            random.shuffle(u_rating_j)\n",
    "            dict_ratings_valid[i] = u_rating_j\n",
    "        \n",
    "        results = []\n",
    "        for num in range(fold):\n",
    "            dict_ratings_valid_train = dict()\n",
    "            dict_ratings_valid_test = dict()\n",
    "            train_set = ratings.copy()\n",
    "            test_set = ratings.copy()\n",
    "            fold_idx = [i for i in range(fold)]\n",
    "            fold_idx.remove(num)\n",
    "            # use dictionary to store each user with ratings\n",
    "            for user_id in dict_ratings_valid.keys():\n",
    "                tmp = [dict_ratings_valid[user_id][i::fold] for i in range(fold)]\n",
    "                dict_ratings_valid_test[user_id] = tmp[num] # test_dict\n",
    "                tr_tmp = []\n",
    "                for idx in fold_idx:\n",
    "                    tr_tmp.extend(tmp[idx]) \n",
    "                dict_ratings_valid_train[user_id] = tr_tmp # train_dict\n",
    "\n",
    "            # get train set\n",
    "            for user_id in dict_ratings_valid_test:\n",
    "                cols = dict_ratings_valid_test[user_id]\n",
    "                train_set.loc[user_id, cols] = np.nan\n",
    "            \n",
    "            # get test set\n",
    "            for user_id in dict_ratings_valid_train:\n",
    "                cols = dict_ratings_valid_train[user_id]\n",
    "                test_set.loc[user_id, cols] = np.nan\n",
    "            \n",
    "            # normolize\n",
    "            if self.normolize:\n",
    "                ratings_mean_tr = np.nanmean(train_set.to_numpy(), axis=1)\n",
    "                ratings_mean_tt = np.nanmean(test_set.to_numpy(), axis=1)\n",
    "                train_set = train_set - ratings_mean_tr.reshape(-1, 1)\n",
    "                test_set = test_set - ratings_mean_tt.reshape(-1, 1)\n",
    "\n",
    "            if save:\n",
    "                joblib.dump(test_set.to_numpy(), 'test_set_' + str(num))\n",
    "                joblib.dump(train_set.to_numpy(), 'train_set_' + str(num))\n",
    "                print('Fold_' + str(num) + ' Saved')\n",
    "            \n",
    "            results.append([train_set.to_numpy(), test_set.to_numpy()])\n",
    "        # results    [x]    [y]    [z]\n",
    "        # format  |k-fold|tr/tst|user_id|\n",
    "        return results\n",
    "\n",
    "class SVD():\n",
    "    def __init__(self, threadID, train_set, test_set, K_features=10, lr=0.005, reg=0.05, epoch=75):\n",
    "        self.threadID =  threadID\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.K_features = K_features\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.epoch = epoch\n",
    "    \n",
    "    # initialize params\n",
    "    def initialize_latent_vectors(self):\n",
    "        # To be reproducible\n",
    "        np.random.seed(33)\n",
    "        self.U = np.random.rand(self.train_set.shape[0], self.K_features)\n",
    "        np.random.seed(33)\n",
    "        self.M = np.random.rand(self.K_features, self.train_set.shape[1])\n",
    "    \n",
    "    # 1) loss function\n",
    "    def MAE(self, dataset):\n",
    "        mask = np.isnan(dataset)\n",
    "        masked_array = ma.array(dataset, mask=mask)\n",
    "        error = masked_array - np.matmul(self.U, self.M)\n",
    "        MAE = np.mean(np.absolute(error))\n",
    "        # MAE = mae(masked_array, np.dot(self.U, self.M))\n",
    "        return MAE\n",
    "\n",
    "    # 2) loss function\n",
    "    def RMSE(self, dataset):\n",
    "        mask = np.isnan(dataset)\n",
    "        masked_array = ma.array(dataset, mask=mask)\n",
    "        error = masked_array - np.matmul(self.U, self.M)\n",
    "        RMSE = np.sqrt((error**2).mean())\n",
    "        # RMSE = mse(masked_array, np.dot(self.U, self.M)) ** 0.5\n",
    "        return RMSE\n",
    "    \n",
    "    def update_params(self, i, j, error):\n",
    "        self.U[i,:] += self.lr * (2 * error * self.M[:,j] - self.reg * self.U[i,:])\n",
    "        self.M[:,j] += self.lr * (2 * error * self.U[i,:] - self.reg * self.M[:,j])\n",
    "    \n",
    "    def save_params(self):\n",
    "        joblib.dump(self.U, 'U_vec'+str(self.threadID))\n",
    "        joblib.dump(self.M, 'M_vec'+str(self.threadID))\n",
    "    \n",
    "    def load_params(self):\n",
    "        self.U = joblib.load('U_vec'+str(self.threadID))\n",
    "        self.M = joblib.load('M_vec'+str(self.threadID))\n",
    "\n",
    "    def testing(self):\n",
    "        MAE = self.MAE(self.test_set)\n",
    "        RMSE = self.RMSE(self.test_set)\n",
    "        print('Thread-->',self.threadID,' Test-->', 'RMSE: ', RMSE, 'MAE: ', MAE)\n",
    "        \n",
    "    # training\n",
    "    def training(self, retrain=False):\n",
    "\n",
    "        if retrain:\n",
    "            self.load_params()\n",
    "            print('Thread-->',self.threadID,' Params loaded')\n",
    "        else:\n",
    "        # initialize params\n",
    "            self.initialize_latent_vectors()\n",
    "\n",
    "        # start training\n",
    "        '''\n",
    "        1) Iterate over each known element \n",
    "        2) update the ith row of U and the jth column of M.\n",
    "        '''\n",
    "        # valid_el = dict()\n",
    "        # for index, el in np.ndenumerate(self.train_set):\n",
    "        #     if isnan(el) == False:\n",
    "        #         valid_el.update({index:el})\n",
    "            \n",
    "        # start training\n",
    "        for epoch in range(self.epoch):\n",
    "            # for coord, rating in valid_el.items():\n",
    "            for index, el in np.ndenumerate(self.train_set):\n",
    "                if isnan(el) == False:\n",
    "                    i = index[0]\n",
    "                    j = index[1]\n",
    "                    pred = np.dot(self.U[i,:], self.M[:, j]) # row vec * col vec  \n",
    "                    error = el - pred # get error\n",
    "                    # update each param item\n",
    "                    self.update_params(i,j, error)\n",
    "                    # self.U[i,:] += self.lr * (2 * error * self.M[:,j] - self.reg * self.U[i,:])\n",
    "                    # self.M[:,j] += self.lr * (2 * error * self.U[i,:] - self.reg * self.M[:,j])\n",
    "                \n",
    "            MAE = self.MAE(self.train_set)\n",
    "            RMSE = self.RMSE(self.train_set)\n",
    "            print(' Epoch',epoch, ' Thread-->',self.threadID,' Train-->', 'RMSE: ', RMSE, 'MAE: ', MAE)\n",
    "            self.testing() # get performance of model on test set\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0  Thread--> 1  Train--> RMSE:  1.0067985715305465 MAE:  0.7854379203386799\n",
      "Thread--> 1  Test--> RMSE:  1.0223616983287411 MAE:  0.7988847002298936\n",
      " Epoch 1  Thread--> 1  Train--> RMSE:  0.9178967396006897 MAE:  0.7250272590175104\n",
      "Thread--> 1  Test--> RMSE:  0.9395231718065548 MAE:  0.7422750680987753\n",
      " Epoch 2  Thread--> 1  Train--> RMSE:  0.912222530488904 MAE:  0.723302811406637\n",
      "Thread--> 1  Test--> RMSE:  0.9367481294782953 MAE:  0.7427041308193976\n",
      " Epoch 3  Thread--> 1  Train--> RMSE:  0.9069467649650452 MAE:  0.7192935344110981\n",
      "Thread--> 1  Test--> RMSE:  0.9344694025931031 MAE:  0.7408991407058291\n",
      " Epoch 4  Thread--> 1  Train--> RMSE:  0.8995148279300396 MAE:  0.7132822488775614\n",
      "Thread--> 1  Test--> RMSE:  0.9304304378155611 MAE:  0.7373464691249414\n",
      " Epoch 5  Thread--> 1  Train--> RMSE:  0.8897734634303736 MAE:  0.7053032365111488\n",
      "Thread--> 1  Test--> RMSE:  0.92451377159244 MAE:  0.7321687100127698\n",
      " Epoch 6  Thread--> 1  Train--> RMSE:  0.8794330365770139 MAE:  0.6968165117854291\n",
      "Thread--> 1  Test--> RMSE:  0.9182242437801651 MAE:  0.7266697255318313\n",
      " Epoch 7  Thread--> 1  Train--> RMSE:  0.8696614833504079 MAE:  0.6888526091814693\n",
      "Thread--> 1  Test--> RMSE:  0.9125691123500109 MAE:  0.7217181427135743\n",
      " Epoch 8  Thread--> 1  Train--> RMSE:  0.8606621927673433 MAE:  0.6815360704511826\n",
      "Thread--> 1  Test--> RMSE:  0.9076415688757141 MAE:  0.7173699569990911\n",
      " Epoch 9  Thread--> 1  Train--> RMSE:  0.8524772554786786 MAE:  0.6748560775663252\n",
      "Thread--> 1  Test--> RMSE:  0.903371634568134 MAE:  0.7135362682178585\n",
      " Epoch 10  Thread--> 1  Train--> RMSE:  0.8451300828057853 MAE:  0.6688267831158797\n",
      "Thread--> 1  Test--> RMSE:  0.8997037399793979 MAE:  0.7101790394158184\n",
      " Epoch 11  Thread--> 1  Train--> RMSE:  0.8385913527385235 MAE:  0.6634366334293511\n",
      "Thread--> 1  Test--> RMSE:  0.8965751073491207 MAE:  0.7072204033270665\n",
      " Epoch 12  Thread--> 1  Train--> RMSE:  0.8327926174643242 MAE:  0.6586268955435709\n",
      "Thread--> 1  Test--> RMSE:  0.8939137305319635 MAE:  0.7046304909590002\n",
      " Epoch 13  Thread--> 1  Train--> RMSE:  0.8276530189022951 MAE:  0.6543462218524421\n",
      "Thread--> 1  Test--> RMSE:  0.891649266093012 MAE:  0.7024056653047351\n",
      " Epoch 14  Thread--> 1  Train--> RMSE:  0.8230940592592366 MAE:  0.6505316365157187\n",
      "Thread--> 1  Test--> RMSE:  0.8897197918475309 MAE:  0.7004992567770413\n",
      " Epoch 15  Thread--> 1  Train--> RMSE:  0.8190444029691798 MAE:  0.64714260154922\n",
      "Thread--> 1  Test--> RMSE:  0.8880732337070544 MAE:  0.698861286637681\n",
      " Epoch 16  Thread--> 1  Train--> RMSE:  0.8154405255594835 MAE:  0.6441325333167996\n",
      "Thread--> 1  Test--> RMSE:  0.8866662927887806 MAE:  0.6974449978542328\n",
      " Epoch 17  Thread--> 1  Train--> RMSE:  0.8122262160732739 MAE:  0.6414501024060223\n",
      "Thread--> 1  Test--> RMSE:  0.8854628149637359 MAE:  0.6962212551355289\n",
      " Epoch 18  Thread--> 1  Train--> RMSE:  0.8093519292603027 MAE:  0.6390487893264172\n",
      "Thread--> 1  Test--> RMSE:  0.8844323700171954 MAE:  0.6951587144511706\n",
      " Epoch 19  Thread--> 1  Train--> RMSE:  0.8067741967768338 MAE:  0.6368924507802948\n",
      "Thread--> 1  Test--> RMSE:  0.8835491897023188 MAE:  0.6942294779906089\n",
      " Epoch 20  Thread--> 1  Train--> RMSE:  0.804455087919764 MAE:  0.6349528570230993\n",
      "Thread--> 1  Test--> RMSE:  0.8827913960403245 MAE:  0.6934253977948834\n",
      " Epoch 21  Thread--> 1  Train--> RMSE:  0.8023616836298817 MAE:  0.6331987904449371\n",
      "Thread--> 1  Test--> RMSE:  0.8821404177919339 MAE:  0.6927333731491601\n",
      " Epoch 22  Thread--> 1  Train--> RMSE:  0.8004655482150435 MAE:  0.6316116597767295\n",
      "Thread--> 1  Test--> RMSE:  0.8815805194389874 MAE:  0.6921328210365132\n",
      " Epoch 23  Thread--> 1  Train--> RMSE:  0.7987422040635821 MAE:  0.6301723642784739\n",
      "Thread--> 1  Test--> RMSE:  0.8810983996012395 MAE:  0.6916148566382769\n",
      " Epoch 24  Thread--> 1  Train--> RMSE:  0.7971706243552926 MAE:  0.6288594901384178\n",
      "Thread--> 1  Test--> RMSE:  0.8806828384686538 MAE:  0.6911614676080553\n",
      " Epoch 25  Thread--> 1  Train--> RMSE:  0.7957327591050035 MAE:  0.6276604849787242\n",
      "Thread--> 1  Test--> RMSE:  0.8803243858984104 MAE:  0.6907642119304394\n",
      " Epoch 26  Thread--> 1  Train--> RMSE:  0.7944131054263801 MAE:  0.6265586666431943\n",
      "Thread--> 1  Test--> RMSE:  0.8800150868541528 MAE:  0.6904173793831165\n",
      " Epoch 27  Thread--> 1  Train--> RMSE:  0.793198327370185 MAE:  0.6255424653997221\n",
      "Thread--> 1  Test--> RMSE:  0.8797482422226833 MAE:  0.6901121569978691\n",
      " Epoch 28  Thread--> 1  Train--> RMSE:  0.7920769260038448 MAE:  0.6246022191017574\n",
      "Thread--> 1  Test--> RMSE:  0.879518202894144 MAE:  0.6898420809857922\n",
      " Epoch 29  Thread--> 1  Train--> RMSE:  0.7910389571675256 MAE:  0.6237284925648986\n",
      "Thread--> 1  Test--> RMSE:  0.8793201944602951 MAE:  0.6896070024291859\n",
      " Epoch 30  Thread--> 1  Train--> RMSE:  0.7900757924854177 MAE:  0.6229144082854183\n",
      "Thread--> 1  Test--> RMSE:  0.8791501694479618 MAE:  0.689398607140482\n",
      " Epoch 31  Thread--> 1  Train--> RMSE:  0.7891799184020523 MAE:  0.622155823490004\n",
      "Thread--> 1  Test--> RMSE:  0.8790046837991884 MAE:  0.6892167221445266\n",
      " Epoch 32  Thread--> 1  Train--> RMSE:  0.7883447679046653 MAE:  0.621447835345442\n",
      "Thread--> 1  Test--> RMSE:  0.8788807943251115 MAE:  0.6890539690144232\n",
      " Epoch 33  Thread--> 1  Train--> RMSE:  0.787564579900076 MAE:  0.6207857386171819\n",
      "Thread--> 1  Test--> RMSE:  0.8787759740368651 MAE:  0.6889090051548284\n",
      " Epoch 34  Thread--> 1  Train--> RMSE:  0.7868342817346963 MAE:  0.6201649345223733\n",
      "Thread--> 1  Test--> RMSE:  0.8786880425300159 MAE:  0.6887809381720085\n",
      " Epoch 35  Thread--> 1  Train--> RMSE:  0.786149390945274 MAE:  0.61958130411317\n",
      "Thread--> 1  Test--> RMSE:  0.8786151089176031 MAE:  0.6886663539552337\n",
      " Epoch 36  Thread--> 1  Train--> RMSE:  0.7855059329242211 MAE:  0.6190337375615033\n",
      "Thread--> 1  Test--> RMSE:  0.8785555251356612 MAE:  0.6885658477314778\n",
      " Epoch 37  Thread--> 1  Train--> RMSE:  0.7849003717326898 MAE:  0.6185172635868432\n",
      "Thread--> 1  Test--> RMSE:  0.8785078477616342 MAE:  0.6884777640122324\n",
      " Epoch 38  Thread--> 1  Train--> RMSE:  0.7843295517765718 MAE:  0.618029731612431\n",
      "Thread--> 1  Test--> RMSE:  0.8784708067777576 MAE:  0.6884013024383496\n",
      " Epoch 39  Thread--> 1  Train--> RMSE:  0.7837906484703403 MAE:  0.6175685269136051\n",
      "Thread--> 1  Test--> RMSE:  0.8784432799725476 MAE:  0.6883379801122681\n",
      " Epoch 40  Thread--> 1  Train--> RMSE:  0.7832811263544239 MAE:  0.6171313357688589\n",
      "Thread--> 1  Test--> RMSE:  0.8784242719016655 MAE:  0.6882862132393525\n",
      " Epoch 41  Thread--> 1  Train--> RMSE:  0.7827987034111554 MAE:  0.6167156504503402\n",
      "Thread--> 1  Test--> RMSE:  0.8784128965255042 MAE:  0.6882423712273003\n",
      " Epoch 42  Thread--> 1  Train--> RMSE:  0.7823413205515213 MAE:  0.6163202406250179\n",
      "Thread--> 1  Test--> RMSE:  0.8784083628068184 MAE:  0.6882072954013011\n",
      " Epoch 43  Thread--> 1  Train--> RMSE:  0.781907115428876 MAE:  0.6159450743255427\n",
      "Thread--> 1  Test--> RMSE:  0.8784099626904047 MAE:  0.6881787355128499\n",
      " Epoch 44  Thread--> 1  Train--> RMSE:  0.7814943998847009 MAE:  0.6155883878203069\n",
      "Thread--> 1  Test--> RMSE:  0.878417061001518 MAE:  0.6881562212049327\n",
      " Epoch 45  Thread--> 1  Train--> RMSE:  0.781101640452335 MAE:  0.6152482471745112\n",
      "Thread--> 1  Test--> RMSE:  0.8784290868934023 MAE:  0.6881383999046314\n",
      " Epoch 46  Thread--> 1  Train--> RMSE:  0.7807274414430178 MAE:  0.6149237858794308\n",
      "Thread--> 1  Test--> RMSE:  0.8784455265504152 MAE:  0.6881242188421242\n",
      " Epoch 47  Thread--> 1  Train--> RMSE:  0.7803705302191718 MAE:  0.6146137677725407\n",
      "Thread--> 1  Test--> RMSE:  0.8784659169141239 MAE:  0.6881130174284591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7712/2795410471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtest_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         )\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7712/3239657414.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, retrain)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# row vec * col vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;31m# get error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[1;31m# update each param item\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = CrossValidation('ratings.dat')\n",
    "train_path = 'train_set_1'\n",
    "test_path = 'test_set_1'\n",
    "train_set, test_set = cv.load_dataset(train_path, test_path)\n",
    "model = SVD(\n",
    "        1,\n",
    "        train_set, \n",
    "        test_set\n",
    "        )\n",
    "model.training(retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uv_ch9 import iniUV, normalize\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def errors(m_true, m_pred, index):\n",
    "  sum1 = 0\n",
    "  sum2 = 0\n",
    "  num = len(index)\n",
    "  for i in index:\n",
    "    e = m_true[i[0]][i[1]] - m_pred[i[0]][i[1]]\n",
    "    sum1 += e**2\n",
    "    sum2 += abs(e)\n",
    "\n",
    "  return np.sqrt(sum1/num), sum2/num\n",
    "\n",
    "\n",
    "# update method in Page 24 of gravity-Tikk.pdf\n",
    "def updateUV(m, u, v, irate, l, train):\n",
    "    # generate e\n",
    "    pred = np.dot(u, v)\n",
    "    for i in train:\n",
    "        error = m[i[0]][i[1]] - pred[i[0]][i[1]]\n",
    "        u[i[0]] = u[i[0]] + irate * (2 * error * v[:, i[1]] - l * u[i[0]])\n",
    "        v[:, i[1]] = v[:, i[1]] + irate * (2 * error * u[i[0]] - l * v[:, i[1]])\n",
    "\n",
    "    return u, v\n",
    "\n",
    "\n",
    "def MF(M, threshold, max_time, k, train, test):\n",
    "    # print(M)\n",
    "    M, means = normalize(M)\n",
    "    # M = M.values\n",
    "    u, v = iniUV(M, k)\n",
    "    for i in range(max_time):\n",
    "        u, v = updateUV(M, u, v, 0.005, 0.05, train)\n",
    "        pred = np.dot(u, v)\n",
    "        r,m = errors(M, pred, train)\n",
    "        print(\"RMSE:\", r, \"MAE:\", m)\n",
    "        if r < threshold:\n",
    "            break\n",
    "\n",
    "    return errors(M, np.dot(u, v), test), r, m\n",
    "\n",
    "\n",
    "def testTrainSplit(M):\n",
    "    index = []\n",
    "    random.seed(0)\n",
    "    M = M.values\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(M.shape[1]):\n",
    "            if M[i, j] == M[i, j]:\n",
    "                index.append((i, j))\n",
    "\n",
    "    i1 = random.sample(index, round(len(index) / 5))\n",
    "    index = list(set(index) - set(i1))\n",
    "    i2 = random.sample(index, round(len(index) / 4))\n",
    "    index = list(set(index) - set(i2))\n",
    "    i3 = random.sample(index, round(len(index) / 3))\n",
    "    index = list(set(index) - set(i3))\n",
    "    i4 = random.sample(index, round(len(index) / 2))\n",
    "    i5 = list(set(index) - set(i4))\n",
    "    train1 = i2 + i3 + i4 + i5\n",
    "    train2 = i1 + i3 + i4 + i5\n",
    "    train3 = i1 + i2 + i4 + i5\n",
    "    train4 = i1 + i2 + i3 + i5\n",
    "    train5 = i1 + i2 + i3 + i4\n",
    "\n",
    "    return [train1, train2, train3, train4, train5], \\\n",
    "           [i1, i2, i3, i4, i5]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load fire\n",
    "    M = {}\n",
    "    with open('ratings.dat', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in reader:\n",
    "            data = line[0].split('::')\n",
    "            if data[0] in M:\n",
    "                M[data[0]][data[1]] = data[2]\n",
    "            else:\n",
    "                M[data[0]] = {data[1]: data[2]}\n",
    "\n",
    "    M = pd.DataFrame(M)\n",
    "    M = M.iloc[:5, :10]\n",
    "    # print(uvDecomposition(M, threshold, max_time,10))\n",
    "\n",
    "    # 5 fold\n",
    "    M = M.astype('float')\n",
    "    M = M.T\n",
    "    train_r = 0\n",
    "    train_m = 0\n",
    "    test_r = 0\n",
    "    test_m = 0\n",
    "    train, test = testTrainSplit(M)\n",
    "    for i in range(5):\n",
    "        e = MF(M, threshold, max_time, 10, train[i], test[i])\n",
    "        print(e)\n",
    "        test_r += e[0][0] / 5\n",
    "        test_m += e[0][1] / 5\n",
    "        train_r += e[1] / 5\n",
    "        train_m += e[2] / 5\n",
    "    print(\"testRMSE:\", test_r,\n",
    "          \"\\ntestMAE:\", test_m,\n",
    "          \"\\ntrainRMSE:\", train_r,\n",
    "          \"\\ntrainMAE:\", train_m)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    max_time = 75\n",
    "    threshold = 0.1\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63ca0c8d3a239235585b09f22bd374cae13a775a92515e346cda6a4d44a7b14d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
