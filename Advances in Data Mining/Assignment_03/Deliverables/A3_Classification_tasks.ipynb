{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0) Problem and Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (0.1) Data Description\n",
    "The source of this dataset we use (Body performance Data) is from [here](https://www.kaggle.com/kukuroo3/body-performance-data/code) (Kaggle).\n",
    "It has 12 columns:\n",
    "Age (20 to 64),\n",
    "Gender (Female and Male),\n",
    "height (cm),\n",
    "weight (kg),\n",
    "body fat (percent),\n",
    "diastolic blood pressure (min),\n",
    "systolic blood pressure (min),\n",
    "grip force,\n",
    "sit and bend forward (cm),\n",
    "sit-ups (counts),\n",
    "broad jump (cm),\n",
    "class (A to D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (0.2) Problem description\n",
    "This dataset reflects people's health levels ranging from A class (best) to D class, in relation to some physical data (e.g., age, diastolic and weight). Therefore, SVM, Randomforest, and XGBoost are introduced to fit this dataset and then predict the health levels given data of physical performance.\n",
    "<br/>\n",
    "<br/> SVM, Randomforest, and XGBoost are all from sklearn package, while GridSearchCV and RandomizedSearchCV are applied to tune the (hyper)parameters. In addition, this dataset contains two columns in which the elements are the String type. Accordingly, we do some conversion and modification on it (See the Data Preprocessing section) before it is taken to train.\n",
    "<br/>\n",
    "<br/> The results of the performance of these three models are shown as classification reports which chiefly include four measures, i.e., f1-score, recall, precision, and accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (0.3) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Exploratory Data Analysis-----\n",
      "(1) Dataset structure: \n",
      "    age  gender  height_cm  weight_kg  body fat_%  diastolic  systolic  \\\n",
      "0  27.0       1      172.3      75.24        21.3       80.0     130.0   \n",
      "1  25.0       1      165.0      55.80        15.7       77.0     126.0   \n",
      "\n",
      "   gripForce  sit and bend forward_cm  sit-ups counts  broad jump_cm class  \n",
      "0       54.9                     18.4            60.0          217.0     C  \n",
      "1       36.4                     16.3            53.0          229.0     A  \n",
      "\n",
      "(2) Shape of dataset (includes the label col): \n",
      "(13393, 12)\n",
      "\n",
      "(3) Shape of train and test sets: \n",
      "Shape of X_train: (9375, 11)\n",
      "Shape of Y_train: (9375,)\n",
      "Shape of X_test: (4018, 11)\n",
      "Shape of Y_test: (4018,)\n",
      "\n",
      "(4) Columns: \n",
      "Index(['age', 'gender', 'height_cm', 'weight_kg', 'body fat_%', 'diastolic',\n",
      "       'systolic', 'gripForce', 'sit and bend forward_cm', 'sit-ups counts',\n",
      "       'broad jump_cm', 'class'],\n",
      "      dtype='object')\n",
      "\n",
      "(5) Length of data:  13393\n"
     ]
    }
   ],
   "source": [
    "# The class of health levels are converted from ABCD to 3210.\n",
    "# To make the gender feature numeric, male and female are changed to 1 and 0, respectively.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dataset = pd.read_csv('bodyPerformance.csv')\n",
    "dataset.gender = [1 if gd == 'M' else 0 for gd in dataset.gender]\n",
    "Y = dataset['class'].values\n",
    "Y = np.array([ord('a')-ord(cls)-29 for cls in Y]).astype('int')\n",
    "X = dataset.drop([\"class\"], axis=1)\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X)).values # normalization\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=132)\n",
    "target_names = ['D', 'C', 'B', 'A']\n",
    "print('-----Exploratory Data Analysis-----')\n",
    "print('(1) Dataset structure: ')\n",
    "print(dataset.head(2))\n",
    "print()\n",
    "print('(2) Shape of dataset (includes the label col): ')\n",
    "print(dataset.shape)\n",
    "print()\n",
    "print('(3) Shape of train and test sets: ')\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of Y_train:', Y_train.shape)\n",
    "print('Shape of X_test:', X_test.shape)\n",
    "print('Shape of Y_test:', Y_test.shape)\n",
    "print()\n",
    "print('(4) Columns: ')\n",
    "print(dataset.columns)\n",
    "print()\n",
    "print('(5) Length of data: ', len(dataset))\n",
    "# print()\n",
    "# print('(6) Data Information: ', dataset.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1.1) Parameter tuning for SVM using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo', random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, decision_function_shape='ovo', gamma=1, random_state=333)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_hyperparams  = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        }\n",
    "\n",
    "svm_randCV = GridSearchCV(svm_clf, svm_hyperparams, cv = 3)\n",
    "svm_randCV.fit(X, Y)\n",
    "svm_randCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1.2) Results of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on bodyperformance dataset: 70.03%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.88      0.78      0.83      1018\n",
      "           C       0.66      0.63      0.65       985\n",
      "           B       0.55      0.59      0.57       967\n",
      "           A       0.73      0.79      0.76      1048\n",
      "\n",
      "    accuracy                           0.70      4018\n",
      "   macro avg       0.70      0.70      0.70      4018\n",
      "weighted avg       0.71      0.70      0.70      4018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_clf = svm.SVC(C=1000, decision_function_shape='ovo', gamma=1, random_state=333)\n",
    "svm_clf.fit(X_train, Y_train)\n",
    "svm_Y_predicted = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test, svm_Y_predicted)\n",
    "print(\"Accuracy of SVM on bodyperformance dataset: %.2f%%\" % (svm_acc * 100.0))\n",
    "print(classification_report(Y_test, svm_Y_predicted, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2.1) Parameter tuning for RandomForest using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=20, max_features='sqrt',\n",
       "                       min_samples_leaf=2, random_state=333)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_hyperparams = {\"n_estimators\": [20, 50, 100],\n",
    "                \"max_depth\": [5, 20, 40, 60, 100],\n",
    "                \"max_features\": ['auto', 'sqrt'] ,\n",
    "                \"min_samples_split\": [2, 4, 6, 8],\n",
    "                \"min_samples_leaf\": [1, 2, 3],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rf_randCV = RandomizedSearchCV(rf_clf, rf_hyperparams, n_iter = 30)\n",
    "rf_randCV.fit(X, Y)\n",
    "rf_randCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2.2) Results of RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest on bodyperformance dataset: 73.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.90      0.81      0.85      1018\n",
      "           C       0.73      0.67      0.70       985\n",
      "           B       0.59      0.61      0.60       967\n",
      "           A       0.72      0.83      0.77      1048\n",
      "\n",
      "    accuracy                           0.73      4018\n",
      "   macro avg       0.74      0.73      0.73      4018\n",
      "weighted avg       0.74      0.73      0.73      4018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "rf_clf = RandomForestClassifier(criterion='entropy', max_depth=20, max_features='sqrt',\n",
    "                       min_samples_leaf=2, random_state=333)\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "rf_Y_predicted = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test, rf_Y_predicted)\n",
    "print(\"Accuracy of RandomForest on bodyperformance dataset: %.2f%%\" % (rf_acc * 100.0))\n",
    "print(classification_report(Y_test, rf_Y_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3.1) Parameter tuning for XGBoost using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(random_state=333, objective='softprob', eval_metric='mlogloss', use_label_encoder =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.875,\n",
       "              enable_categorical=False, eval_metric='mlogloss', gamma=0.4,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.19, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=60, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=333,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.875,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparams  = {\n",
    "        'n_estimators': range(0, 220, 20),\n",
    "        'max_depth': range(3, 10, 1),\n",
    "        'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "        'subsample': np.linspace(0.5, 1, 5),\n",
    "        'colsample_bytree': np.linspace(0.5, 1, 5),\n",
    "        'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "        }\n",
    "\n",
    "xgb_randCV = RandomizedSearchCV(xgb_clf, xgb_hyperparams, random_state=333, cv = 3, scoring = 'neg_log_loss', n_iter = 30)\n",
    "xgb_randCV.fit(X, Y)\n",
    "xgb_randCV.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3.2) Results of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on bodyperformance dataset: 74.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.92      0.83      0.87      1018\n",
      "           C       0.74      0.67      0.71       985\n",
      "           B       0.60      0.63      0.61       967\n",
      "           A       0.74      0.84      0.79      1048\n",
      "\n",
      "    accuracy                           0.75      4018\n",
      "   macro avg       0.75      0.74      0.75      4018\n",
      "weighted avg       0.75      0.75      0.75      4018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.875,\n",
    "              enable_categorical=False, eval_metric='mlogloss', gamma=0.4,\n",
    "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.19, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=60, n_jobs=16, num_parallel_tree=1,\n",
    "              objective='multi:softprob', predictor='auto', random_state=333,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.875,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1)\n",
    "xgb_clf.fit(X_train, Y_train)\n",
    "xgb_Y_predicted = xgb_clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, xgb_Y_predicted)\n",
    "print(\"Accuracy of XGBoost on bodyperformance dataset: %.2f%%\" % (acc * 100.0))\n",
    "print(classification_report(Y_test, xgb_Y_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Conclusion\n",
    "\n",
    "We found from the results of the classification reports that the performance of the Randomforest and XGBoost models are similar (73.32% and 74.64%, respectively) on this dataset for the multi-classification tasks. XGBoost, however, has better results with an accuracy of around 75% over the other two models, while the accuracy on prediction for SVM is about 70%. Additionally, all three models are good at predicting the health class 'D' but falling down on predicting the health class 'B'.\n",
    "<br/>\n",
    "<br/> \n",
    "These three models all show the ability to deal with multi-classification tasks but are still not ideal. Perhaps using a Convolutional neural network or its variants (e.g. ResNet) is capable of substantially improving the results."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63ca0c8d3a239235585b09f22bd374cae13a775a92515e346cda6a4d44a7b14d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
